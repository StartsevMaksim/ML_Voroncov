{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9cbaca9-c1f2-4de6-b000-ac2ecdbe378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from collections import deque\n",
    "from sklearn.metrics import root_mean_squared_error, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "743c48ff-b546-49e0-b548-9a16d00c9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ирисы\n",
    "data_1 = pd.read_csv('DATA/iris.csv').sample(frac=1)\n",
    "X = data_1.drop('species', axis=1)\n",
    "y = data_1['species'].map({'setosa':0, 'versicolor':1, 'virginica':2})\n",
    "X_tensor = torch.from_numpy(X.values)\n",
    "y_tensor = torch.from_numpy(y.values).type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "423da712-38e2-4a69-a5a0-de99d0130600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    \"\"\"\n",
    "    Слой линейных регрессий(нейронов) с выбором функции активации\n",
    "    Параметры\n",
    "    --------\n",
    "    in_features: int\n",
    "        Размерность предыдущего слоя. Если текущий слой первый, то размерность входного вектора\n",
    "\n",
    "    out_features: int\n",
    "        Размерность текущего слоя(размерность вектора на выходе слоя)\n",
    "        \n",
    "    activation_function: {'linear', 'ReLU', 'Tanh'}\n",
    "        Вид функции активации\n",
    "\n",
    "    start_weights: {'zeros', 'random', 'xavier_uniform'}\n",
    "        Способ инициализации начальных весов и смещения нейронов\n",
    "\n",
    "    bias: {True, False}, default=True\n",
    "        Включает смещение в модель нейрона\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 activation_function,\n",
    "                 start_weights,\n",
    "                 bias=True):\n",
    "        self.activation_function = activation_function\n",
    "        self.weights_ = self._start_weights_type[start_weights](in_features, (in_features, out_features))\n",
    "        self.bias_ = self._start_weights_type[start_weights](in_features, (out_features,)) if bias else None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'Linear(in_dim={self.weights_.shape[0]}, '\n",
    "                f'out_dim={self.weights_.shape[1]}, '\n",
    "                f'activation_F={self.activation_function})')\n",
    "    \n",
    "    def findNeuronsOutput(self, x):\n",
    "        output = self.weights_.T @ x\n",
    "        if self.bias_ is not None:\n",
    "            output += self.bias_\n",
    "        return output\n",
    "\n",
    "    def findLayerOutput(self, neurons_out):\n",
    "        return self._activation_function_type[self.activation_function](neurons_out)\n",
    "\n",
    "    def findLayerDerivativeOutput(self, neurons_out):\n",
    "        return self._activation_function_dir_type[self.activation_function](neurons_out)\n",
    "\n",
    "    def layerForward(self, x):\n",
    "        neurons_output = self.findNeuronsOutput(x)\n",
    "        self.dir_output_ = self.findLayerDerivativeOutput(neurons_output)\n",
    "        return self.findLayerOutput(neurons_output)\n",
    "\n",
    "    def layerBackward(self, prev_layer):\n",
    "        self.error_ = prev_layer.weights_ @ (prev_layer.error_ * prev_layer.dir_output_) \n",
    "\n",
    "    def layerStep(self, x, lr):\n",
    "        error_dir = self.error_ * self.dir_output_\n",
    "        self.weights_ -= lr * (x.reshape(-1,1) @ error_dir.reshape(1,-1))\n",
    "        if self.bias_ is not None:\n",
    "            self.bias_ -= lr * error_dir\n",
    "\n",
    "    def setError(self, error):\n",
    "        self.error_ = error\n",
    "    \n",
    "    @staticmethod\n",
    "    def _zeroStartWeights(in_dim, shape):\n",
    "        return torch.zeros(shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def _randomStartWeights(in_dim, shape):\n",
    "        return torch.randn(shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def _xavierUniformStartWeights(in_dim, shape):\n",
    "        k = np.sqrt(1/in_dim)\n",
    "        return torch.rand(shape) * torch.sign(torch.rand(shape)-0.5) * k\n",
    "\n",
    "    @staticmethod\n",
    "    def _linActivationF(y):\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def _reLUActivationF(y):\n",
    "        return torch.where(y>=0, y, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tanhActivationF(y):\n",
    "        return torch.tanh(y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _dirLinActivationF(y):\n",
    "        return torch.ones(y.shape[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def _dirReLUActivationF(y):\n",
    "        return torch.where(y>=0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dirTanhActivationF(y):\n",
    "        return -torch.pow(torch.tanh(y), 2) + 1\n",
    "\n",
    "    _start_weights_type = {'zeros': _zeroStartWeights,\n",
    "                           'random': _randomStartWeights,\n",
    "                           'xavier_uniform': _xavierUniformStartWeights}\n",
    "    _activation_function_type = {'linear': _linActivationF,\n",
    "                                 'ReLU': _reLUActivationF,\n",
    "                                 'Tanh': _tanhActivationF}\n",
    "    _activation_function_dir_type = {'linear': _dirLinActivationF,\n",
    "                                     'ReLU': _dirReLUActivationF,\n",
    "                                     'Tanh': _dirTanhActivationF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6130d440-b4ee-456c-8cdd-624375ca43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerSequential:\n",
    "    \"\"\"\n",
    "    Класс для реализации последовательности слоев нейронной сети с проходом вперед и назад.\n",
    "    Возможен выбор Функции потерь: square(для регрессии), log(для классификации)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.layers_name = []\n",
    "        self.layers = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ''.join([f'({layer_name}): {layer}\\n'\n",
    "                        for layer_name, layer in zip(self.layers_name, self.layers)])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.layers[index]\n",
    "    \n",
    "    def add_module(self, layer_name, layer):\n",
    "        self.layers_name.append(layer_name)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.layers_output = [x]\n",
    "        for layer_name, layer in zip(self.layers_name, self.layers):\n",
    "            x = layer.layerForward(x)\n",
    "            self.layers_output.append(x)\n",
    "\n",
    "    def backward(self, y, loss_function):\n",
    "        model_error = self._loss_function_dir_type[loss_function](self.layers[-1].output_, y)\n",
    "        self.layers[-1].setError(model_error)\n",
    "        prev_layer = self.layers[-1]\n",
    "        for layer in self.layers[-2::-1]:\n",
    "            layer.layerBackward(prev_layer)\n",
    "            prev_layer = layer\n",
    "\n",
    "    def step(self, x, lr):\n",
    "        for layer in self.layers:\n",
    "            layer.layerStep(x, lr)\n",
    "            x = layer.output_\n",
    "        \n",
    "    @staticmethod\n",
    "    def _dirSquareError(x, y):\n",
    "        return (x - y)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dirLogError(x, y):\n",
    "        return -y * torch.exp(-y*x) / (1 + torch.exp(-y*x))\n",
    "    \n",
    "    _loss_function_dir_type = {'square': _dirSquareError,\n",
    "                               'log': _dirLogError}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f870b3eb-05d8-498c-8c60-2a21da22807e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0191, -0.2633,  0.2120],\n",
       "        [ 0.0221, -0.2682,  0.2238],\n",
       "        [ 0.0691, -0.3964,  0.2203],\n",
       "        [ 0.0763, -0.3999,  0.2097],\n",
       "        [ 0.0442, -0.3544,  0.1890],\n",
       "        [ 0.0519, -0.3608,  0.2166],\n",
       "        [ 0.0415, -0.3205,  0.2112],\n",
       "        [ 0.0582, -0.3586,  0.2215],\n",
       "        [ 0.0261, -0.2902,  0.2210],\n",
       "        [ 0.0433, -0.3351,  0.2016],\n",
       "        [ 0.0564, -0.3797,  0.2229],\n",
       "        [ 0.0183, -0.2698,  0.1998],\n",
       "        [ 0.0260, -0.2785,  0.2347],\n",
       "        [ 0.0501, -0.3420,  0.2037],\n",
       "        [ 0.0876, -0.4554,  0.1878],\n",
       "        [ 0.0605, -0.3852,  0.2015],\n",
       "        [ 0.0401, -0.3304,  0.1995],\n",
       "        [ 0.0705, -0.4186,  0.2249],\n",
       "        [ 0.0191, -0.2645,  0.2110],\n",
       "        [ 0.0682, -0.3927,  0.2013],\n",
       "        [ 0.0842, -0.4347,  0.2269],\n",
       "        [ 0.0615, -0.3918,  0.1922],\n",
       "        [ 0.0204, -0.2690,  0.2130],\n",
       "        [ 0.0167, -0.2610,  0.2008],\n",
       "        [ 0.0450, -0.3440,  0.2068],\n",
       "        [ 0.0535, -0.3584,  0.2129],\n",
       "        [ 0.0807, -0.4344,  0.1844],\n",
       "        [ 0.0166, -0.2654,  0.1951],\n",
       "        [ 0.0576, -0.3826,  0.2103],\n",
       "        [ 0.0385, -0.3272,  0.2005],\n",
       "        [ 0.0097, -0.2644,  0.1719],\n",
       "        [ 0.0627, -0.3783,  0.2050],\n",
       "        [ 0.0745, -0.4200,  0.1969],\n",
       "        [ 0.0723, -0.3931,  0.2220],\n",
       "        [ 0.0912, -0.4736,  0.1675],\n",
       "        [ 0.0918, -0.4493,  0.2208],\n",
       "        [ 0.0464, -0.3394,  0.2132],\n",
       "        [ 0.0540, -0.3581,  0.2007],\n",
       "        [ 0.0630, -0.3725,  0.1737],\n",
       "        [ 0.0571, -0.3708,  0.2285],\n",
       "        [ 0.0482, -0.3562,  0.2188],\n",
       "        [ 0.0762, -0.4208,  0.2147],\n",
       "        [ 0.0511, -0.3393,  0.2139],\n",
       "        [ 0.0215, -0.2612,  0.2289],\n",
       "        [ 0.0414, -0.3301,  0.2285],\n",
       "        [ 0.0476, -0.3383,  0.2150],\n",
       "        [ 0.0462, -0.3316,  0.2207],\n",
       "        [ 0.0291, -0.2844,  0.2461],\n",
       "        [ 0.0609, -0.3771,  0.1968],\n",
       "        [ 0.0208, -0.2685,  0.2160],\n",
       "        [ 0.0574, -0.3824,  0.2278],\n",
       "        [ 0.0604, -0.3639,  0.2060],\n",
       "        [ 0.0743, -0.4157,  0.2127],\n",
       "        [ 0.0165, -0.2635,  0.1964],\n",
       "        [ 0.0595, -0.3672,  0.1941],\n",
       "        [ 0.0085, -0.2378,  0.1918],\n",
       "        [ 0.0592, -0.3785,  0.2073],\n",
       "        [ 0.0849, -0.4616,  0.2032],\n",
       "        [ 0.0226, -0.2846,  0.2071],\n",
       "        [ 0.0251, -0.2731,  0.2358],\n",
       "        [ 0.0698, -0.4122,  0.2167],\n",
       "        [ 0.0607, -0.3869,  0.2220],\n",
       "        [ 0.0497, -0.3306,  0.2123],\n",
       "        [ 0.0677, -0.3866,  0.2046],\n",
       "        [ 0.0881, -0.4613,  0.1766],\n",
       "        [ 0.0774, -0.4177,  0.2091],\n",
       "        [ 0.0199, -0.2679,  0.2113],\n",
       "        [ 0.0302, -0.3061,  0.2195],\n",
       "        [ 0.0197, -0.2663,  0.2124],\n",
       "        [ 0.0572, -0.3581,  0.2028],\n",
       "        [ 0.0203, -0.2725,  0.2080],\n",
       "        [ 0.0428, -0.3385,  0.1933],\n",
       "        [ 0.0444, -0.3416,  0.2133],\n",
       "        [ 0.0167, -0.2610,  0.2008],\n",
       "        [ 0.0121, -0.2427,  0.1956],\n",
       "        [ 0.0242, -0.2663,  0.2384],\n",
       "        [ 0.0591, -0.3683,  0.1917],\n",
       "        [ 0.0308, -0.2985,  0.2053],\n",
       "        [ 0.0151, -0.2531,  0.2011],\n",
       "        [ 0.0232, -0.2766,  0.2205],\n",
       "        [ 0.0323, -0.3110,  0.1847],\n",
       "        [ 0.0504, -0.3504,  0.2234],\n",
       "        [ 0.0739, -0.4052,  0.2146],\n",
       "        [ 0.0243, -0.2788,  0.2239],\n",
       "        [ 0.0574, -0.3802,  0.2126],\n",
       "        [ 0.0472, -0.3341,  0.2178],\n",
       "        [ 0.0583, -0.3663,  0.2140],\n",
       "        [ 0.0192, -0.2601,  0.2167],\n",
       "        [ 0.0666, -0.3958,  0.2111],\n",
       "        [ 0.0127, -0.2394,  0.2030],\n",
       "        [ 0.0467, -0.3335,  0.1948],\n",
       "        [ 0.0149, -0.2500,  0.2034],\n",
       "        [ 0.0122, -0.2442,  0.1946],\n",
       "        [ 0.0548, -0.3592,  0.2141],\n",
       "        [ 0.0655, -0.3947,  0.1941],\n",
       "        [ 0.0170, -0.2591,  0.2048],\n",
       "        [ 0.0777, -0.4291,  0.2005],\n",
       "        [ 0.0675, -0.3863,  0.1931],\n",
       "        [ 0.0595, -0.3672,  0.1941],\n",
       "        [ 0.0599, -0.3713,  0.2124],\n",
       "        [ 0.0224, -0.2773,  0.2151],\n",
       "        [ 0.0720, -0.4154,  0.2150],\n",
       "        [ 0.0609, -0.3944,  0.2066],\n",
       "        [ 0.0237, -0.2869,  0.2108],\n",
       "        [ 0.0520, -0.3760,  0.1901],\n",
       "        [ 0.0662, -0.3918,  0.2218],\n",
       "        [ 0.0183, -0.2650,  0.2056],\n",
       "        [ 0.0312, -0.3046,  0.2019],\n",
       "        [ 0.0563, -0.3736,  0.1719],\n",
       "        [ 0.0763, -0.4154,  0.2200],\n",
       "        [ 0.0533, -0.3695,  0.2182],\n",
       "        [ 0.0192, -0.2539,  0.2241],\n",
       "        [ 0.0167, -0.2610,  0.2008],\n",
       "        [ 0.0224, -0.2721,  0.2212],\n",
       "        [ 0.0142, -0.2421,  0.2085],\n",
       "        [ 0.0275, -0.2912,  0.2284],\n",
       "        [ 0.0781, -0.4230,  0.2032],\n",
       "        [ 0.0160, -0.2478,  0.2125],\n",
       "        [ 0.0217, -0.2640,  0.2269],\n",
       "        [ 0.0179, -0.2541,  0.2160],\n",
       "        [ 0.0644, -0.3956,  0.2134],\n",
       "        [ 0.0172, -0.2668,  0.1965],\n",
       "        [ 0.0639, -0.3969,  0.2188],\n",
       "        [ 0.0580, -0.3682,  0.1888],\n",
       "        [ 0.0624, -0.3957,  0.2272],\n",
       "        [ 0.0419, -0.3337,  0.2020],\n",
       "        [ 0.0554, -0.3525,  0.2350],\n",
       "        [ 0.0799, -0.4418,  0.1871],\n",
       "        [ 0.0692, -0.3849,  0.2246],\n",
       "        [ 0.0591, -0.3686,  0.2285],\n",
       "        [ 0.0222, -0.2590,  0.2353],\n",
       "        [ 0.0703, -0.4026,  0.1952],\n",
       "        [ 0.0210, -0.2708,  0.2144],\n",
       "        [ 0.0152, -0.2582,  0.1950],\n",
       "        [ 0.0224, -0.2722,  0.2211],\n",
       "        [ 0.0165, -0.2528,  0.2092],\n",
       "        [ 0.0582, -0.3809,  0.1892],\n",
       "        [ 0.0720, -0.4134,  0.2077],\n",
       "        [ 0.0232, -0.2814,  0.2148],\n",
       "        [ 0.0531, -0.3791,  0.1854],\n",
       "        [ 0.0555, -0.3615,  0.2076],\n",
       "        [ 0.0450, -0.3378,  0.2058],\n",
       "        [ 0.0464, -0.3374,  0.2059],\n",
       "        [ 0.0893, -0.4510,  0.2268],\n",
       "        [ 0.0386, -0.3313,  0.2152],\n",
       "        [ 0.0148, -0.2484,  0.2044],\n",
       "        [ 0.0710, -0.4119,  0.1749],\n",
       "        [ 0.0462, -0.3224,  0.1903],\n",
       "        [ 0.0697, -0.4000,  0.1938],\n",
       "        [ 0.0733, -0.4048,  0.1995]], dtype=torch.float64,\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = torch.nn.Sequential()\n",
    "layers.add_module('lin1', torch.nn.Linear(4, 6, dtype=torch.float64))\n",
    "layers.add_module('relu1', torch.nn.ReLU())\n",
    "layers.add_module('lin2', torch.nn.Linear(6, 6, dtype=torch.float64))\n",
    "layers.add_module('relu2', torch.nn.ReLU())\n",
    "layers.add_module('res', torch.nn.Linear(6, 3, dtype=torch.float64))\n",
    "layers(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a3a9104-7786-45f6-8679-c535473713bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (6x4 and 150x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m uLayers\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlin2\u001b[39m\u001b[38;5;124m'\u001b[39m, LinearLayer(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReLU\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxavier_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m uLayers\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m, LinearLayer(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxavier_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m \u001b[43muLayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[52], line 24\u001b[0m, in \u001b[0;36mLayerSequential.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_output \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayerForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_output\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "Cell \u001b[1;32mIn[51], line 49\u001b[0m, in \u001b[0;36mLinearLayer.layerForward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlayerForward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 49\u001b[0m     neurons_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindNeuronsOutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir_output_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfindLayerDerivativeOutput(neurons_output)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfindLayerOutput(neurons_output)\n",
      "Cell \u001b[1;32mIn[51], line 37\u001b[0m, in \u001b[0;36mLinearLayer.findNeuronsOutput\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindNeuronsOutput\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 37\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (6x4 and 150x4)"
     ]
    }
   ],
   "source": [
    "uLayers = LayerSequential()\n",
    "uLayers.add_module('lin1', LinearLayer(4,6,'ReLU','xavier_uniform'))\n",
    "uLayers.add_module('lin2', LinearLayer(6,6,'ReLU','xavier_uniform'))\n",
    "uLayers.add_module('res', LinearLayer(4,6,'linear','xavier_uniform'))\n",
    "uLayers.forward(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766fb04-56b4-4d78-98e7-6704d687e53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
