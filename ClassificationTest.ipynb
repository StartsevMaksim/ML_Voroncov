{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32864cbd-b575-475e-a906-d623344df6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from collections import deque\n",
    "#from ULogicalModels import UDecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "513382fc-c121-4a7e-813b-13fd53984d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelError(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    return classification_report(y_test, y_predict)\n",
    "    \n",
    "def compareModels(model, uModel, X, y, is_need_scale):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "    if is_need_scale:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    model_error = getModelError(model, X_train, X_test, y_train, y_test)\n",
    "    uModel_error = getModelError(uModel, X_train, X_test, y_train, y_test)\n",
    "    print('Ошибка на пакетной модели\\n', model_error)\n",
    "    print('Ошибка на реализованной модели\\n', uModel_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "905fa891-75ad-4aba-b052-2ee59e3fbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вины\n",
    "data_1 = pd.read_csv('DATA/wine_fraud.csv')\n",
    "X = data_1.drop(['type','quality'], axis=1)\n",
    "y = data_1['type']\n",
    "y = y.map({'red': 1, 'white': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f426efd6-622b-4d06-b3f4-2e9b9e687aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Исследование слуха\n",
    "data_1 = pd.read_csv('DATA/hearing_test.csv')\n",
    "X = data_1.drop('test_result', axis=1)\n",
    "y = data_1['test_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20430f89-3e4b-4960-a650-141722887dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ирисы\n",
    "data_1 = pd.read_csv('DATA/iris.csv')\n",
    "X = data_1.drop('species', axis=1)\n",
    "y = data_1['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5fb6a73-d250-4fe6-b44c-901b97393a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(n_estimators=10)\n",
    "uModel = UAdaBoost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7db11be4-c49c-47a5-a1e3-34d5068b175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на пакетной модели\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99      1451\n",
      "           1       0.98      0.97      0.97       499\n",
      "\n",
      "    accuracy                           0.99      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.99      0.99      0.99      1950\n",
      "\n",
      "Ошибка на реализованной модели\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99      1451\n",
      "           1       0.97      0.98      0.97       499\n",
      "\n",
      "    accuracy                           0.99      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.99      0.99      0.99      1950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "compareModels(model, uModel, X, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c16f7-4ef3-4da7-9933-75c4a521a27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167200a-1644-4932-9cbf-41cd035c3f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc03298f-ba6e-4909-ab26-a996d8c1fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim=11, \n",
    "                 num_layers=0,\n",
    "                 hiden_dim=30, \n",
    "                 output_dim=3,\n",
    "                 p=0.0,\n",
    "                 device='cpu'):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        prev_size = input_dim\n",
    "        for i in range(num_layers):\n",
    "            self.layers.add_module(f'layer{i+1}',\n",
    "                                   torch.nn.Linear(prev_size, hiden_dim)) #Шаблон вычисления слоя\n",
    "            self.layers.add_module(f'tanh{i+1}',\n",
    "                                   torch.nn.Tanh()) #Сигма функция(функция активации)\n",
    "            self.layers.add_module(f'dropout{i+1}',\n",
    "                                   torch.nn.Dropout(p=p)) #Удаление нейрона с вероятностью p\n",
    "            prev_size = hiden_dim\n",
    "        self.layers.add_module('classifier',\n",
    "                               torch.nn.Linear(prev_size, output_dim)) #Выход сети\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2110303d-e01c-40fa-beb2-e74decf6d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение модели\n",
    "def trainer(model, X, y, loss_function, optimizer, epochs):\n",
    "    for epoch in range(epochs): #Кол-во итераций\n",
    "        optimizer.zero_grad()\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#Тестрирование модели\n",
    "def testing(model, X):    \n",
    "    X = X.to(device)\n",
    "    y_pred = torch.argmax(model(X), dim=1)\n",
    "    return y_pred\n",
    "\n",
    "#Преобразуем в Tensor\n",
    "def getTensor(X, y):\n",
    "    X_tensor = torch.from_numpy(X.values.astype(np.float32))\n",
    "    y_tensor = torch.from_numpy(y.values.astype(np.int64))\n",
    "    return X_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "497b104e-dd82-4858-8da6-ac50a1dd5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e1645c-23b1-4104-8e73-767c67736e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Устройство, на котором будут выполняться вычисления\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11285acd-df7f-404b-963d-4913a72cfb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разбиение выборки на Train и Test\n",
    "data_1 = pd.read_csv('DATA/wine_fraud.csv')\n",
    "X = data_1.drop(['type','quality'], axis=1)\n",
    "y = data_1['type']\n",
    "y = y.map({'red': 2, 'white': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "X_train, y_train = getTensor(X_train, y_train)\n",
    "X_test, y_test = getTensor(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6e045ab-bf26-4418-a28d-8de34830772c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5197, 11]), torch.Size([1300, 11]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b6ab13b-920e-46e4-8f6f-f9f1fee88b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание модели\n",
    "model = Perceptron(num_layers=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f196253-ec01-4c6c-bc36-5e89f1876ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение\n",
    "_ = model.train()\n",
    "#trainer(model=model,\n",
    "#        X=X_train,\n",
    "#        y=y_train,\n",
    "#        loss_function=torch.nn.CrossEntropyLoss(),\n",
    "#        optimizer=torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "#        epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0425663c-8cb9-4443-9aaf-9cc01d0c79a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       971\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.74      0.41      0.53       329\n",
      "\n",
      "    accuracy                           0.10      1300\n",
      "   macro avg       0.25      0.14      0.18      1300\n",
      "weighted avg       0.19      0.10      0.13      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SMD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SMD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SMD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SMD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\SMD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "_ = model.eval()\n",
    "y_pred = testing(model, X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f1969f4-2204-4d4d-8e12-f0c9b6e2fda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(\n",
       "  (layers): Sequential(\n",
       "    (classifier): Linear(in_features=11, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97f1d144-6da4-4eb7-ad93-e795110bcd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сверточные Нейронные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10b49ba-8382-45b4-b6cc-424fb86b2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "\n",
    "    output = model(x_batch.to('cpu'))\n",
    "\n",
    "    loss = loss_function(output, y_batch.to('cpu'))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d72d310-5e7c-4f3b-a94d-bb5d78c975cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_generator, model, loss_function, optimizer, callback=None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x.to('cpu'), batch_of_y.to('cpu'), optimizer, loss_function)\n",
    "\n",
    "        if callback is not None:\n",
    "            callback(model, batch_loss)\n",
    "\n",
    "        epoch_loss += batch_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b1023f-a55d-4624-bfb9-b0d2f4ec5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(count_of_epoch,\n",
    "            batch_size,\n",
    "            dataset,\n",
    "            model,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr=0.001,\n",
    "            callback=None):\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "    for it in range(count_of_epoch):\n",
    "        batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = train_epoch(train_generator=batch_generator,\n",
    "                                 model=model,\n",
    "                                 loss_function=loss_function,\n",
    "                                 optimizer=optima,\n",
    "                                 callback=callback)\n",
    "        print(f'Эпоха {it}: ошибка = {epoch_loss}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75569a37-946f-42bf-a840-c35555892114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tester(model, dataset, batch_size):\n",
    "    batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "    y_predict = []\n",
    "    y_real = []\n",
    "    for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "        x_batch = x_batch.to('cpu')\n",
    "        y_batch = y_batch.to('cpu')\n",
    "\n",
    "        output = model(x_batch)\n",
    "        y_predict.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "        y_real.extend(y_batch.cpu().numpy().tolist())\n",
    "    print(classification_report(y_real, y_predict))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1571f8aa-78a9-4f56-9b37-ef9b3da0295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for param in self.parameters():\n",
    "            return param.device\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*6, kernel_size=5)) #Кол-во входных каналов(признаков, которые \n",
    "                                                                                #описывают объект)\n",
    "                                                                                #Кол-во выходных каналов(признаков) \n",
    "                                                                                #Размер сверточного ядра(Оно сжимает изображение)\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU()) #Функция активации\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size=2)) #Сжимает изображение ещё в 2 раза\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*6, 1*16, kernel_size=5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten()) #Вытягиваем тензор в один вектор\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*4*4, 120))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 10))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca77234-a12e-4faf-9fa4-7f129eb07417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение модели CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d5eb41-25eb-49b3-9dde-c0437e18aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка данных\n",
    "MNIST_train = datasets.MNIST('DATA/mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "MNIST_test = datasets.MNIST('DATA/mnist', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be2d43f-29b1-45d2-a936-4e81865e77d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layers): Sequential(\n",
       "    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (relu1): ReLU()\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (relu2): ReLU()\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear1): Linear(in_features=256, out_features=120, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (linear2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (relu4): ReLU()\n",
       "    (linear3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "model = CNN()\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d146c8c6-5882-4e60-bff0-abc1944b7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0: ошибка = 0.33032608373363814\n"
     ]
    }
   ],
   "source": [
    "#Обучение CNN\n",
    "trainer(count_of_epoch=1,\n",
    "        batch_size=64,\n",
    "        dataset=MNIST_train,\n",
    "        model=model,\n",
    "        loss_function=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        lr=0.001,\n",
    "        callback=None) #callback - позволяет отслеживать обучение модели(логирование). Используется TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be93a3e-e10c-4cfd-92d2-5edf365d6326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.99      0.97      0.98      1135\n",
      "           2       0.98      0.96      0.97      1032\n",
      "           3       0.98      0.93      0.96      1010\n",
      "           4       0.99      0.95      0.97       982\n",
      "           5       0.95      0.97      0.96       892\n",
      "           6       0.97      0.99      0.98       958\n",
      "           7       0.97      0.96      0.96      1028\n",
      "           8       0.91      0.98      0.94       974\n",
      "           9       0.94      0.97      0.95      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.97      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester(model=model,\n",
    "       dataset=MNIST_test,\n",
    "       batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82fb6728-62fe-41cc-9915-b6846e226c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выбрали случайно объект\n",
    "x = data[torch.randint(data.shape[0], size=(1,))].reshape(-1,)\n",
    "#Выходы нейронов\n",
    "neuron_outputs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc207424-6eb6-409b-9554-70a5bc161d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8000e+00, 1.8000e-01, 2.8000e-01, 1.1000e+00, 2.7000e-02, 3.2000e+01,\n",
       "        1.1200e+02, 9.9089e-01, 3.1500e+00, 4.5000e-01, 1.1000e+01])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "251a7a97-8336-4608-bc9c-8b7da1cf2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "weigths = torch.Tensor([[[-4,5,7],\n",
    "                         [2,-3,1]],\n",
    "                        [[9,2,3],\n",
    "                         [1,3,1]]\n",
    "                       ])\n",
    "x = torch.Tensor([2,-1,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edabf85d-ce31-4f57-87fa-6418d2dd3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = weigths[0] @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8da60889-a64b-49b8-b6c2-3ba83a6432a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-27.,   5.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d63aab-abec-41e2-9cd5-ecf6b2f4fc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4a7ab-3092-48be-9eb9-347d68ace9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3272d-69d4-47d7-9f82-1e2f820ba5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = x\n",
    "hiden_layers\n",
    "output_layer = Linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c18bf9f5-86f9-4fe6-9c1c-985cfaf8ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 activation_function='ReLU',\n",
    "                 start_weights='random'):\n",
    "        self.activation_function = activation_function\n",
    "        self.weights_ = self._start_weights_type[start_weights](in_features, out_features)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'Linear(in_dim={self.weights_.shape[0]}, '\n",
    "                f'out_dim={self.weights_.shape[1]}, '\n",
    "                f'activation_F={self.activation_function})')\n",
    "\n",
    "    def findNeuronsOutput(self, x):\n",
    "        return self.weights_.T @ x\n",
    "    \n",
    "    def findLayerOutput(self, neurons_out):\n",
    "        return self._activation_function_type[self.activation_function](neurons_out)\n",
    "\n",
    "    def findLayerDerivativeOutput(self, neurons_out):\n",
    "        return self._activation_function_dir_type[self.activation_function](neurons_out)\n",
    "\n",
    "    @staticmethod\n",
    "    def _zeroStartWeights(rows, cols):\n",
    "        return torch.zeros((rows, cols)).type(torch.float64)\n",
    "\n",
    "    @staticmethod\n",
    "    def _randomStartWeights(rows, cols):\n",
    "        return torch.rand((rows, cols)).type(torch.float64)\n",
    "\n",
    "    @staticmethod\n",
    "    def _linActivationF(y):\n",
    "        return y.type(torch.float64)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _reLUActivationF(y):\n",
    "        return torch.where(y>=0, y, 0).type(torch.float64)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dirLinActivationF(y):\n",
    "        return torch.ones(y.shape[0]).type(torch.float64)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dirReLUActivationF(y):\n",
    "        return torch.where(y>=0, 1, 0).type(torch.float64)\n",
    "\n",
    "    _start_weights_type = {'zeros': _zeroStartWeights,\n",
    "                           'random': _randomStartWeights}\n",
    "    _activation_function_type = {'linear': _linActivationF,\n",
    "                                 'ReLU': _reLUActivationF}\n",
    "    _activation_function_dir_type = {'linear': _dirLinActivationF,\n",
    "                                     'ReLU': _dirReLUActivationF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e14f1746-bd3a-4cba-b397-eb9c8e9c3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#МОЖЕТ ХРАНИТЬ ВСЕ ВЫХОДЫ СЛОЯ В СЛОЕ\n",
    "class LayerSequential:\n",
    "    def __init__(self):\n",
    "        self.layers_name = []\n",
    "        self.layers = []\n",
    "\n",
    "    def add_module(self, layer_name, layer):\n",
    "        self.layers_name.append(layer_name)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layers_outs, layers_dir_outs = [], []\n",
    "        for layer in self.layers:\n",
    "            neurons_output = layer.findNeuronsOutput(x)\n",
    "            layer_output = layer.findLayerOutput(neurons_output)\n",
    "            layer_dir_output = layer.findLayerDerivativeOutput(neurons_output)\n",
    "            layers_outs.append(layer_output)\n",
    "            layers_dir_outs.append(layer_dir_output)\n",
    "            x = layer_output\n",
    "        return (self._getTensor(layers_outs),\n",
    "                self._getTensor(layers_dir_outs))\n",
    "\n",
    "    def backward(self, layers_outs, layers_dir_outs, x, y, loss_function='square'):\n",
    "        errors = self._loss_function_dir_type[loss_function](layers_outs[-1], y).reshape(1,-1)\n",
    "        layers_weights = list(layer.weights_ for layer in self.layers)\n",
    "        for weights, layer_dir in zip(layers_weights[::-1], torch.flip(layers_dir_outs[1:], dims=[0])):\n",
    "            layer_error = (weights @ (errors[0] * layer_dir)).reshape(1,-1)\n",
    "            errors = torch.cat([layer_error,errors])\n",
    "        \n",
    "        for index, (weights, error, layer_dir, layer_out) in enumerate(zip(layers_weights,\n",
    "                                                                           errors,\n",
    "                                                                           layers_dir_outs,\n",
    "                                                                           torch.roll(layers_outs, 1, 0))):\n",
    "            \n",
    "            print(index)\n",
    "            print(weights)\n",
    "            print(error)\n",
    "            print(layer_dir)\n",
    "            print(layer_out)\n",
    "            \n",
    "\n",
    "    @staticmethod\n",
    "    def _getTensor(array):\n",
    "        return torch.cat([x.reshape(1,-1) for x in array]) \n",
    "\n",
    "    @staticmethod\n",
    "    def _dirSquareError(x, y):\n",
    "        return (x - y).type(torch.float64)\n",
    "    \n",
    "    _loss_function_dir_type = {'square': _dirSquareError}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9135ad-6b61-4324-a22f-f9ac528dbe75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1c02befd-56ea-41e4-b3b7-eb0f3d9f1ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[0.1035, 0.0193, 0.8211],\n",
      "        [0.1392, 0.8908, 0.5626],\n",
      "        [0.5488, 0.3482, 0.4688],\n",
      "        [0.2668, 0.0305, 0.6823]], dtype=torch.float64)\n",
      "tensor([53.9990, 14.1581, 64.4954], dtype=torch.float64)\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n",
      "tensor([3.3533, 4.1650, 6.5698], dtype=torch.float64)\n",
      "1\n",
      "tensor([[0.6114, 0.1829, 0.9269],\n",
      "        [0.3190, 0.0971, 0.0210],\n",
      "        [0.7845, 0.6657, 0.4578]], dtype=torch.float64)\n",
      "tensor([30.0246, 40.5639, 30.4494], dtype=torch.float64)\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n",
      "tensor([8.5328, 5.3911, 6.2035], dtype=torch.float64)\n",
      "2\n",
      "tensor([[0.8672, 0.4053, 0.4849],\n",
      "        [0.6829, 0.8926, 0.4924],\n",
      "        [0.7565, 0.0333, 0.9303]], dtype=torch.float64)\n",
      "tensor([ 9.5283, 24.8650, 24.0942], dtype=torch.float64)\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n",
      "tensor([15.7735,  8.4764, 12.5634], dtype=torch.float64)\n",
      "3\n",
      "tensor([[0.1082, 0.4144, 0.1250],\n",
      "        [0.3305, 0.6105, 0.7159],\n",
      "        [0.4146, 0.3749, 0.8372]], dtype=torch.float64)\n",
      "tensor([ 8.7175, 15.4220, 17.5567], dtype=torch.float64)\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n",
      "tensor([ 9.7175, 16.4220, 18.5567], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([2,3,4,2]).type(torch.float64)\n",
    "y = torch.Tensor([1,1,1]).type(torch.float64)\n",
    "layers = LayerSequential()\n",
    "layers.add_module('Linear1', LinearLayer(4,3))\n",
    "layers.add_module('Linear2', LinearLayer(3,3))\n",
    "layers.add_module('Linear3', LinearLayer(3,3))\n",
    "layers.add_module('Linear4', LinearLayer(3,3))\n",
    "layers_outs, layers_dir_outs = layers.forward(x)\n",
    "layers.backward(layers_outs, layers_dir_outs, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49417db8-b765-42cb-b2b6-ba4056ee81ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not reversible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_weights, layer_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m, layers_dir_outs[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(layer_weights, layer_dir)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not reversible"
     ]
    }
   ],
   "source": [
    "for layer_weights, layer_dir in zip(reversed(layer.weights_ for layer in layers.layers), layers_dir_outs[::-1]):\n",
    "    print(layer_weights, layer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a759a90-6a37-418b-8f6a-301bbdfdc87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.7175, 16.4220, 18.5567],\n",
       "        [ 3.3533,  4.1650,  6.5698],\n",
       "        [ 8.5328,  5.3911,  6.2035],\n",
       "        [15.7735,  8.4764, 12.5634]], dtype=torch.float64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.roll(layers_outs, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eae3875e-de30-444d-af92-40bf5292e5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.7124, 0.9020, 0.1245],\n",
       "         [0.8411, 0.1967, 0.1525],\n",
       "         [0.5350, 0.6078, 0.9847]]),\n",
       " tensor([[0.9152, 0.7722, 0.2059],\n",
       "         [0.7328, 0.4468, 0.8606],\n",
       "         [0.1081, 0.6390, 0.8466]]),\n",
       " tensor([[0.2375, 0.6820, 0.3395],\n",
       "         [0.7870, 0.7744, 0.4389],\n",
       "         [0.1797, 0.8624, 0.8896]]),\n",
       " tensor([[0.1215, 0.9102, 0.6717],\n",
       "         [0.0553, 0.3966, 0.5961],\n",
       "         [0.9424, 0.1465, 0.6675],\n",
       "         [0.3407, 0.9053, 0.1807]])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer.weights_ for layer in layers.layers][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a928b1c7-7083-4893-991f-1becd65034e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(layer.weights_ for layer in layers.layers[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa3ac763-5665-4df0-a3f1-f66e4b374063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0003f060-3fe6-420a-a23f-db87309e22a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3,2]).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1c32c-0f8c-4d38-a007-f1c322755b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
