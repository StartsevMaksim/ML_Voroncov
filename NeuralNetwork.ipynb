{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73aaf39f-e151-42bb-9dcf-c398b40e6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import root_mean_squared_error, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import UNeuralNetwork as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b31873-b2a0-40e9-ad13-bddc59b0f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "\n",
    "    output = model(x_batch.to('cpu'))  \n",
    "    loss = loss_function(output, y_batch.to('cpu'))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()  \n",
    "\n",
    "def train_epoch(train_generator, model, loss_function, optimizer, callback=None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x.to('cpu'), batch_of_y.to('cpu'), optimizer, loss_function)\n",
    "\n",
    "        if callback is not None:\n",
    "            callback(model, batch_loss)\n",
    "\n",
    "        epoch_loss += batch_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "\n",
    "    return epoch_loss / total\n",
    "\n",
    "def trainer(count_of_epoch,\n",
    "            batch_size,\n",
    "            dataset,\n",
    "            model,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr=0.001,\n",
    "            callback=None):\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "    for it in range(count_of_epoch):\n",
    "        batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = train_epoch(train_generator=batch_generator,\n",
    "                                 model=model,\n",
    "                                 loss_function=loss_function,\n",
    "                                 optimizer=optima,\n",
    "                                 callback=callback)\n",
    "        print(f'Эпоха {it+1}: ошибка = {epoch_loss}') \n",
    "\n",
    "def tester(model, dataset, batch_size):\n",
    "    batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "    y_predict = []\n",
    "    y_real = []\n",
    "    for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "        x_batch = x_batch.to('cpu')\n",
    "        y_batch = y_batch.to('cpu')\n",
    "\n",
    "        output = model(x_batch)\n",
    "        y_predict.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "        y_real.extend(y_batch.cpu().numpy().tolist())\n",
    "    print(classification_report(y_real, y_predict))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d302e9b4-6073-44ed-96ba-1d84169c0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for param in self.parameters():\n",
    "            return param.device\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 6, kernel_size=5))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(6, 16, kernel_size=5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten())\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*4*4, 120))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 10))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8464ced-b909-4288-80fe-5dcbba0b117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка данных\n",
    "df = pd.read_csv('DATA/MNIST.csv').sample(2000, axis=0)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label'].to_numpy(dtype=np.int64)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=101)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32).reshape(-1,1,28,28))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32).reshape(-1,1,28,28))\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "data_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "data_test = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd752b5-83fe-4799-ade9-3b03de9fdee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD\n",
    "\n",
    "model = CNN().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d171bb75-0adc-476a-9531-4f72e38be890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1: ошибка = 2.254660213694853\n",
      "Эпоха 2: ошибка = 1.7230839359059054\n",
      "Эпоха 3: ошибка = 1.1147982070025275\n",
      "Эпоха 4: ошибка = 0.5382336270107942\n",
      "Эпоха 5: ошибка = 0.40615982090725616\n"
     ]
    }
   ],
   "source": [
    "#Обучение CNN\n",
    "trainer(count_of_epoch=5,\n",
    "        batch_size=64,\n",
    "        dataset=data_train,\n",
    "        model=model,\n",
    "        loss_function=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        lr=0.1,\n",
    "        callback=None) #callback - позволяет отслеживать обучение модели(логирование). Используется TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60577c97-54ac-4a2d-ad08-09bfad1675ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        26\n",
      "           1       0.94      1.00      0.97        31\n",
      "           2       0.81      0.85      0.83        26\n",
      "           3       0.86      0.83      0.84        23\n",
      "           4       0.66      0.93      0.77        29\n",
      "           5       0.87      0.92      0.89        36\n",
      "           6       0.97      0.94      0.96        36\n",
      "           7       0.79      0.92      0.85        36\n",
      "           8       0.90      0.93      0.91        28\n",
      "           9       0.91      0.34      0.50        29\n",
      "\n",
      "    accuracy                           0.86       300\n",
      "   macro avg       0.87      0.85      0.84       300\n",
      "weighted avg       0.87      0.86      0.85       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester(model=model,\n",
    "       dataset=data_test,\n",
    "       batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21886ec-9ed8-456c-90d7-34f992b1ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCNN:\n",
    "    def __init__(self):\n",
    "        self.layers = nn.USequential()\n",
    "        self.layers.add_module('conv1', nn.UConv2d(1, 6, kernel_size=5))\n",
    "        self.layers.add_module('relu1', nn.UReLU())\n",
    "        self.layers.add_module('pool1', nn.UMaxPool2d(kernel_size=2))\n",
    "        self.layers.add_module('conv2', nn.UConv2d(6, 16, kernel_size=5))\n",
    "        self.layers.add_module('relu2', nn.UReLU())\n",
    "        self.layers.add_module('pool2', nn.UMaxPool2d(kernel_size=2))\n",
    "        self.layers.add_module('flatten', nn.UFlatten())\n",
    "        self.layers.add_module('linear1', nn.ULinear(16*4*4, 120))\n",
    "        self.layers.add_module('relu3', nn.UReLU())\n",
    "        self.layers.add_module('linear2', nn.ULinear(120, 84))\n",
    "        self.layers.add_module('relu4', nn.UReLU())\n",
    "        self.layers.add_module('linear3', nn.ULinear(84, 10))\n",
    "\n",
    "    def _train_epoch(self, batch_generator):\n",
    "        for batch_of_x, batch_of_y in batch_generator:\n",
    "            for X, y in zip(batch_of_x, batch_of_y):\n",
    "                output = self.layers.forward(X)\n",
    "                self.layers.backward(output, y, 'CEL')\n",
    "                self.layers.step(0.001)\n",
    "            print('Batch ready')\n",
    "    \n",
    "    def train(self, dataset, batch_size, count_of_epoch):\n",
    "        for epoch_no in range(count_of_epoch):\n",
    "            batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "            self._train_epoch(batch_generator)\n",
    "            print(f'Эпоха {epoch_no+1} завершена')\n",
    "\n",
    "    def test(self, dataset, batch_size):\n",
    "        batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "        y_predict, y_real = [], []\n",
    "        for x_batch, y_batch in batch_generator:\n",
    "            for X, y in zip(batch_of_x, batch_of_y):\n",
    "                output = self.layers.forward(X)\n",
    "                y_predict.extend(torch.argmax(output, dim=-1).numpy().tolist())\n",
    "                y_real.extend(y.numpy().tolist())\n",
    "        print(classification_report(y_real, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6bba3d-b80f-4170-a004-130692bd5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uModel = UCNN()\n",
    "uModel.train(data_train, 64, 5)\n",
    "uModel.test(data_test, 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
