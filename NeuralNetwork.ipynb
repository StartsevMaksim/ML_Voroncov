{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73aaf39f-e151-42bb-9dcf-c398b40e6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from collections import deque\n",
    "from sklearn.metrics import root_mean_squared_error, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from UNeuralNetwork import LayerSequential, LinearLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b31873-b2a0-40e9-ad13-bddc59b0f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "\n",
    "    output = model(x_batch.to('cpu'))  \n",
    "    loss = loss_function(output, y_batch.to('cpu'))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()  \n",
    "\n",
    "def train_epoch(train_generator, model, loss_function, optimizer, callback=None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x.to('cpu'), batch_of_y.to('cpu'), optimizer, loss_function)\n",
    "\n",
    "        if callback is not None:\n",
    "            callback(model, batch_loss)\n",
    "\n",
    "        epoch_loss += batch_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "\n",
    "    return epoch_loss / total\n",
    "\n",
    "def trainer(count_of_epoch,\n",
    "            batch_size,\n",
    "            dataset,\n",
    "            model,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr=0.001,\n",
    "            callback=None):\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "    for it in range(count_of_epoch):\n",
    "        batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = train_epoch(train_generator=batch_generator,\n",
    "                                 model=model,\n",
    "                                 loss_function=loss_function,\n",
    "                                 optimizer=optima,\n",
    "                                 callback=callback)\n",
    "        print(f'Эпоха {it}: ошибка = {epoch_loss}') \n",
    "\n",
    "def tester(model, dataset, batch_size):\n",
    "    batch_generator = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "    y_predict = []\n",
    "    y_real = []\n",
    "    for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "        x_batch = x_batch.to('cpu')\n",
    "        y_batch = y_batch.to('cpu')\n",
    "\n",
    "        output = model(x_batch)\n",
    "        y_predict.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "        y_real.extend(y_batch.cpu().numpy().tolist())\n",
    "    print(classification_report(y_real, y_predict))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d302e9b4-6073-44ed-96ba-1d84169c0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for param in self.parameters():\n",
    "            return param.device\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('conv1', torch.nn.Conv2d(1, 1*1, kernel_size=5)) #Кол-во входных каналов(признаков, которые \n",
    "                                                                                #описывают объект)\n",
    "                                                                                #Кол-во выходных каналов(признаков) \n",
    "                                                                                #Размер сверточного ядра(Оно сжимает изображение)\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU()) #Функция активации\n",
    "        self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size=2)) #Сжимает изображение ещё в 2 раза\n",
    "        self.layers.add_module('conv2', torch.nn.Conv2d(1*1, 1*1, kernel_size=5))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('pool2', torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten()) #Вытягиваем тензор в один вектор\n",
    "        self.layers.add_module('linear1', torch.nn.Linear(16*4*4, 120))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear2', torch.nn.Linear(120, 84))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('linear3', torch.nn.Linear(84, 10))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8464ced-b909-4288-80fe-5dcbba0b117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка данных\n",
    "MNIST_train = datasets.MNIST('DATA/mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "MNIST_test = datasets.MNIST('DATA/mnist', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd752b5-83fe-4799-ade9-3b03de9fdee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layers): Sequential(\n",
       "    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (relu1): ReLU()\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (relu2): ReLU()\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear1): Linear(in_features=256, out_features=120, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (linear2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (relu4): ReLU()\n",
       "    (linear3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "model = CNN()\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d171bb75-0adc-476a-9531-4f72e38be890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0: ошибка = 0.3092773442973693\n"
     ]
    }
   ],
   "source": [
    "#Обучение CNN\n",
    "trainer(count_of_epoch=1,\n",
    "        batch_size=64,\n",
    "        dataset=MNIST_train,\n",
    "        model=model,\n",
    "        loss_function=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        lr=0.001,\n",
    "        callback=None) #callback - позволяет отслеживать обучение модели(логирование). Используется TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60577c97-54ac-4a2d-ad08-09bfad1675ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.99      0.99      1135\n",
      "           2       0.99      0.95      0.97      1032\n",
      "           3       0.92      0.99      0.95      1010\n",
      "           4       0.99      0.97      0.98       982\n",
      "           5       0.97      0.96      0.96       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.96      0.96      1028\n",
      "           8       0.99      0.93      0.96       974\n",
      "           9       0.96      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tester(model=model,\n",
    "       dataset=MNIST_test,\n",
    "       batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657b9669-80b2-4ca8-8c50-7be1bb10e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[[1,0,3,5,3,7,6,3],\n",
    "                   [9,4,3,8,1,3,2,1],\n",
    "                   [0,3,5,2,0,5,6,4],\n",
    "                   [3,1,5,0,3,4,3,3],\n",
    "                   [2,2,0,1,0,1,2,0],\n",
    "                   [0,2,1,0,2,3,4,3]],\n",
    "                  [[7,6,3,2,0,1,2,1],\n",
    "                   [1,2,7,4,2,3,2,7],\n",
    "                   [3,4,2,0,2,0,1,2],\n",
    "                   [0,1,2,0,0,4,3,0],\n",
    "                   [0,1,9,1,9,2,3,2],\n",
    "                   [9,1,2,3,9,0,2,1]]],\n",
    "                 dtype=torch.float32)\n",
    "y = torch.tensor([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7572da4f-2fb4-40c4-bf50-92cff3d3a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DLayer:\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 activation_function,\n",
    "                 start_weights,\n",
    "                 bias=True):\n",
    "        self.activation_function = activation_function\n",
    "        self.weights_ = self._start_weights_type[start_weights]((out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias_ = self._start_weights_type[start_weights](out_channels,)\n",
    "\n",
    "    @staticmethod\n",
    "    def _makeConvolution(X_channel, kernel):\n",
    "        k = kernel.shape[0]\n",
    "        n = X_channel.shape[0] - k + 1\n",
    "        m = X_channel.shape[1] - k + 1\n",
    "        return torch.tensor([[torch.sum(X_channel[row:row+k, col:col+k]*kernel) for col in range(m)]\n",
    "                             for row in range(n)]).reshape(1,n,m)\n",
    "\n",
    "    def _makeNextImgChannel(self, X, kernels_for_channel, bias):\n",
    "        result = torch.sum(torch.cat([self._makeConvolution(X_channel, kernel)\n",
    "                                      for X_channel, kernel in zip(X, kernels_for_channel)]),\n",
    "                           dim=-3) + bias\n",
    "        n, m = result.shape\n",
    "        return result.reshape(1,n,m)\n",
    "\n",
    "    def _applyActivationFunction(self, X):\n",
    "        return self._activation_function_type[self.activation_function](X)\n",
    "    \n",
    "    def layerForward(self, X):\n",
    "        next_img = torch.cat([self._makeNextImgChannel(X, kernels_for_channels, bias)\n",
    "                              for kernels_for_channels, bias in zip(self.weights_, self.bias_)])\n",
    "        next_img = self._applyActivationFunction(next_img)\n",
    "        return next_img\n",
    "\n",
    "    @staticmethod\n",
    "    def _linActivationF(X):\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def _reLUActivationF(X):\n",
    "        return torch.where(X>=0, X, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tanhActivationF(X):\n",
    "        return torch.tanh(X)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _zeroStartWeights(shape):\n",
    "        return torch.zeros(shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def _randomStartWeights(shape):\n",
    "        return torch.randn(shape)\n",
    "    \n",
    "    _start_weights_type = {'zeros': _zeroStartWeights,\n",
    "                           'random': _randomStartWeights}\n",
    "\n",
    "    _activation_function_type = {'linear': _linActivationF,\n",
    "                                 'ReLU': _reLUActivationF,\n",
    "                                 'Tanh': _tanhActivationF}\n",
    "\n",
    "class MaxPool2DLayer:\n",
    "    def __init__(self, kernel_size=2):\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def layerForward(self, X):\n",
    "        return torch.cat([self._maxPooling(X_channel) for X_channel in X])\n",
    "    \n",
    "    def _maxPooling(self, X_channel):\n",
    "        result = torch.tensor([[torch.max(X_channel[row:row+self.kernel_size, col:col+self.kernel_size]) \n",
    "                                for col in range(0, X_channel.shape[1], self.kernel_size)]\n",
    "                               for row in range(0, X_channel.shape[0], self.kernel_size)])\n",
    "        return result.reshape(1, result.shape[0], result.shape[1])\n",
    "\n",
    "class FlattenLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def layerForward(self, X):\n",
    "        return X.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "582648c1-6663-4162-91d3-c2a1c69128a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TargetModel, self).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        #self.layers.add_module('conv1', torch.nn.Conv2d(2, 3, kernel_size=3))\n",
    "        #self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        #self.layers.add_module('pool1', torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten(start_dim=0))\n",
    "        self.layers.add_module('linear', torch.nn.Linear(96, 10))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "\n",
    "    def getConvParams(self):\n",
    "        return self.layers[0].weight, self.layers[0].bias\n",
    "\n",
    "    def getLinearParams(self):\n",
    "        return self.layers[-1].weight.T, self.layers[-1].bias\n",
    "\n",
    "    def getModelParams(self):\n",
    "        #print(f'-Сверточный слой\\nВеса\\n{self.layers[0].weight.data}\\nСмещение\\n{self.layers[0].bias.data}')\n",
    "        print(f'-Линейный слой\\nВеса\\n{self.layers[-1].weight.data}\\nСмещение\\n{self.layers[-1].bias.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eaf69661-f0c7-4007-855f-de391ff8ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Линейный слой\n",
      "Веса\n",
      "tensor([[ 2.7271e-02, -3.9024e-02, -7.6870e-02, -8.4852e-02, -8.7422e-02,\n",
      "          4.9037e-02,  8.6713e-02,  1.1280e-02,  4.7331e-02,  3.4262e-02,\n",
      "          5.2248e-02,  1.5519e-02,  1.0155e-02, -4.3080e-02, -4.6640e-02,\n",
      "          3.5887e-02,  3.0978e-03, -8.9695e-02,  2.1046e-02, -8.6393e-02,\n",
      "          3.4132e-02,  5.3289e-02,  6.0717e-02, -5.8975e-02,  1.8473e-02,\n",
      "         -3.6538e-02, -2.7966e-02, -3.1913e-02, -4.2121e-02,  5.6044e-02,\n",
      "          9.8480e-03,  5.2663e-02,  7.5648e-02,  3.3057e-02, -6.8974e-02,\n",
      "         -7.3703e-02,  7.8590e-02, -7.5823e-02, -3.2988e-03,  1.1066e-02,\n",
      "         -8.7328e-02, -6.9823e-02,  4.3512e-03, -2.0492e-02, -7.9301e-02,\n",
      "          7.0097e-03,  5.3983e-02, -4.9685e-02,  8.6616e-02, -2.7284e-03,\n",
      "         -8.2172e-02, -6.6727e-02, -8.4523e-02, -6.2193e-02, -1.1092e-02,\n",
      "          6.5158e-02, -5.8784e-02,  2.4282e-02,  1.4000e-02, -1.0186e-01,\n",
      "          1.6187e-02,  4.3798e-02,  1.9325e-02,  6.4360e-02,  3.9979e-02,\n",
      "          9.5176e-02, -6.1737e-02, -8.8338e-02, -4.8319e-02, -9.5714e-02,\n",
      "          7.0410e-02,  4.3122e-02,  6.6154e-05, -3.5441e-02, -5.1666e-02,\n",
      "         -7.1146e-02, -6.8859e-02,  7.5077e-02, -7.7980e-02,  9.8919e-02,\n",
      "         -5.2085e-02,  5.6891e-02, -8.5908e-02, -5.4344e-02, -4.5202e-02,\n",
      "         -6.3976e-02,  2.4216e-02,  8.3688e-02, -1.6769e-02, -2.4917e-03,\n",
      "         -1.8832e-02,  7.0140e-02,  7.8306e-02,  5.4377e-03,  9.3595e-03,\n",
      "          9.3360e-03],\n",
      "        [-7.8247e-02,  1.4289e-02,  9.0592e-02,  5.6736e-02,  8.9345e-02,\n",
      "          5.8295e-02, -7.6555e-02, -9.5051e-02, -8.1876e-02, -2.9514e-02,\n",
      "         -8.3557e-02, -8.1763e-02,  9.7544e-02, -2.0240e-02, -9.5827e-02,\n",
      "         -7.3159e-02,  4.4030e-02, -2.0350e-03, -8.2822e-02, -7.2751e-02,\n",
      "         -5.0763e-02, -2.8384e-02, -1.2251e-02,  7.4381e-02,  1.0552e-02,\n",
      "          5.2245e-02, -2.4975e-02,  6.0560e-02, -6.1739e-02, -5.3621e-03,\n",
      "          7.6279e-02,  6.6242e-02, -4.6243e-02, -8.6204e-02,  5.9516e-02,\n",
      "          3.4709e-03, -2.5985e-02,  2.2906e-04, -2.6338e-02,  1.3391e-02,\n",
      "         -3.6247e-02, -7.0114e-04, -2.4839e-02, -4.6397e-02,  2.3515e-02,\n",
      "          3.2364e-02,  9.0399e-02,  1.2400e-03,  5.2852e-02,  8.8264e-02,\n",
      "         -8.6321e-02,  4.1373e-02, -2.8825e-02, -8.3736e-02,  5.2193e-02,\n",
      "          8.8394e-02,  2.7431e-02,  3.2833e-02,  1.0180e-01, -5.0035e-02,\n",
      "         -4.7363e-02,  8.4628e-02, -4.3488e-02,  1.6082e-02,  3.4070e-02,\n",
      "          1.0067e-01, -1.0029e-01, -5.8814e-02, -9.7350e-02,  1.9382e-02,\n",
      "         -8.1837e-03,  8.7612e-02,  8.1304e-02, -5.5171e-02, -8.7454e-02,\n",
      "          1.8585e-03,  1.4712e-02,  5.9045e-02, -4.6467e-02, -2.3880e-02,\n",
      "          4.4957e-02, -7.2864e-02, -8.0129e-02,  2.9127e-02, -1.3426e-02,\n",
      "          5.3148e-02, -8.5008e-02, -7.9131e-02, -2.2962e-02, -7.1883e-02,\n",
      "         -5.4186e-02, -6.5483e-02,  4.1402e-02, -9.7010e-02,  8.6777e-02,\n",
      "          6.7065e-02],\n",
      "        [-6.7018e-02,  4.7316e-02,  3.0751e-02,  6.1906e-02,  9.5259e-02,\n",
      "         -6.4033e-02,  5.6496e-02, -1.0659e-02, -9.4911e-02,  7.2209e-02,\n",
      "         -6.4250e-02, -1.7878e-02, -5.9173e-02, -8.5031e-02,  2.8822e-03,\n",
      "          3.5062e-03, -1.2791e-02,  6.8542e-02,  6.0279e-02, -8.8227e-03,\n",
      "          4.5894e-02, -9.8400e-02,  1.6140e-02, -6.0230e-03, -7.7600e-02,\n",
      "          8.7966e-02, -7.3053e-02,  6.9932e-02,  3.4175e-02, -4.5445e-02,\n",
      "          4.1971e-02,  3.8019e-04, -7.7478e-02, -1.0138e-01, -6.8772e-02,\n",
      "          9.3931e-02,  4.5022e-02, -4.3329e-02,  4.2928e-02,  6.8057e-02,\n",
      "          5.8799e-02,  9.9973e-02,  7.5143e-02, -9.1598e-02, -8.0776e-02,\n",
      "          4.1110e-02, -6.7597e-02, -4.6283e-03,  6.0041e-02,  2.1868e-02,\n",
      "         -7.5304e-02,  6.4523e-02, -2.2996e-02, -4.7130e-03,  8.1042e-02,\n",
      "         -2.0478e-02, -8.5849e-02,  3.0576e-02,  6.9819e-02,  2.0422e-02,\n",
      "          9.7710e-02,  3.4337e-02,  6.7416e-02,  8.9583e-02,  5.2928e-02,\n",
      "         -5.7250e-02, -7.8013e-02,  6.0746e-02, -2.9611e-02,  2.9043e-02,\n",
      "         -3.7868e-02,  4.4988e-02,  3.1188e-02,  9.7997e-02,  2.1670e-02,\n",
      "          7.7443e-02,  4.2709e-03, -4.9177e-02,  9.3448e-03,  1.5483e-02,\n",
      "          3.5917e-02, -7.1445e-03,  5.3306e-02, -6.8048e-02,  7.2347e-03,\n",
      "         -2.7956e-02, -5.1912e-02,  8.0377e-02, -9.2247e-02, -4.7601e-02,\n",
      "         -4.8412e-03,  6.2181e-02, -1.0692e-02,  4.8536e-02, -4.5745e-02,\n",
      "          5.0049e-02],\n",
      "        [ 8.8777e-02,  1.0198e-01,  6.1943e-02, -6.9725e-02,  5.8136e-02,\n",
      "          8.0544e-02, -5.9371e-02,  6.7453e-02,  5.6826e-02,  1.6553e-02,\n",
      "          7.5646e-02,  6.1530e-02,  1.2343e-02,  4.2725e-02,  6.5352e-02,\n",
      "          5.9203e-02, -2.7819e-02, -2.9591e-02,  1.6057e-02, -3.2161e-02,\n",
      "         -4.9574e-02, -8.0380e-02,  7.4439e-02, -1.2266e-02,  9.6591e-02,\n",
      "          9.5785e-02, -6.3566e-02,  7.1131e-02, -6.5845e-02,  8.3816e-02,\n",
      "         -4.2058e-02, -5.5752e-02, -1.2222e-02, -6.2603e-02, -8.7639e-03,\n",
      "         -8.8850e-02, -6.7678e-02, -5.4666e-02, -5.0444e-02, -4.4076e-02,\n",
      "          6.9979e-02,  9.3756e-02,  9.3586e-02, -5.8646e-03, -7.9864e-02,\n",
      "          9.0971e-02,  2.6585e-02, -7.1140e-02, -4.0847e-02, -5.4600e-02,\n",
      "         -3.8907e-02, -8.9181e-02, -2.9015e-02,  1.5052e-02, -8.2764e-02,\n",
      "          1.6201e-02,  5.5164e-02, -2.6938e-02, -9.2726e-03, -6.9954e-02,\n",
      "         -8.2412e-03, -9.2979e-02, -6.4533e-02, -7.5706e-02,  9.0059e-02,\n",
      "          4.6186e-02,  8.8059e-02,  8.1465e-03,  9.7482e-02, -6.7180e-02,\n",
      "          1.6649e-03,  1.0005e-03,  4.0573e-02, -6.4442e-02,  6.1392e-02,\n",
      "         -2.8363e-02, -4.0783e-02, -2.7988e-02, -9.6346e-03, -5.9800e-03,\n",
      "         -3.2325e-02, -1.6872e-02, -8.2725e-02,  9.1461e-02,  5.2162e-02,\n",
      "         -9.4534e-02, -4.7924e-02, -1.6054e-02, -8.4123e-02, -6.3397e-02,\n",
      "          2.2814e-02, -6.6439e-02,  3.7162e-02, -9.4516e-02,  4.9716e-03,\n",
      "          2.8159e-02],\n",
      "        [ 2.4237e-02, -9.7159e-02, -5.8191e-03,  7.9705e-02,  6.5144e-02,\n",
      "          2.5255e-02,  2.4557e-03, -4.3409e-03,  5.8908e-02,  7.5374e-02,\n",
      "         -8.6548e-02,  4.5322e-02, -9.9606e-02,  6.0148e-02,  7.6744e-02,\n",
      "          2.5668e-03,  8.4053e-02, -7.7156e-02,  3.7161e-02,  3.5379e-02,\n",
      "          7.4510e-02,  3.1257e-02,  3.5041e-02,  7.5969e-02,  1.2274e-02,\n",
      "         -9.3622e-03, -9.0618e-02, -2.5214e-02,  4.2532e-02,  1.0601e-03,\n",
      "         -1.7208e-02,  7.5408e-03, -1.6816e-02, -1.0286e-02,  3.5575e-02,\n",
      "          1.9332e-02,  6.3382e-03, -5.4709e-04, -7.0546e-02, -9.5294e-02,\n",
      "         -7.7403e-02, -4.1583e-02,  4.8825e-02,  4.5896e-02,  9.4092e-03,\n",
      "          1.0014e-01, -9.0523e-03, -4.3098e-03, -3.8636e-03, -1.1557e-02,\n",
      "         -6.1411e-02,  3.1222e-02, -4.3998e-02, -9.8644e-02, -5.1946e-02,\n",
      "         -7.8356e-02, -6.7410e-02,  2.2347e-02, -8.2442e-02, -4.2188e-02,\n",
      "         -3.3827e-02,  1.5790e-02, -7.5045e-02,  8.4379e-02,  9.3891e-02,\n",
      "          6.7957e-02,  5.8855e-02,  8.4255e-02, -8.8706e-03, -1.6771e-04,\n",
      "         -4.0108e-02,  8.2242e-02,  2.7944e-02,  9.3192e-02,  9.2578e-02,\n",
      "         -8.2912e-02,  2.1858e-02, -4.2994e-02, -9.2554e-02,  5.4741e-02,\n",
      "          9.3544e-02, -1.0008e-01,  6.6471e-02, -3.6769e-02, -4.1176e-02,\n",
      "          1.7579e-02, -6.3753e-02, -3.6334e-02,  4.2145e-02,  2.9880e-02,\n",
      "          8.4022e-04, -4.0975e-02, -3.1405e-02, -1.9219e-03, -5.1209e-04,\n",
      "         -8.6094e-02],\n",
      "        [ 2.8199e-02,  2.5394e-02,  5.3156e-02, -9.2848e-02, -3.3731e-03,\n",
      "          2.6020e-02, -7.5511e-02,  9.6645e-02,  2.9894e-02, -4.4386e-02,\n",
      "         -1.7870e-02,  4.8942e-02,  9.7752e-02, -7.8068e-02, -9.4246e-02,\n",
      "         -5.2864e-02,  4.4657e-02, -9.7695e-03, -7.8001e-02, -1.8884e-02,\n",
      "         -2.6516e-02, -9.4660e-02, -2.6128e-02,  6.1039e-02, -8.7879e-02,\n",
      "         -7.6321e-02,  8.7869e-02, -4.4885e-02, -5.2554e-02,  1.0130e-03,\n",
      "          5.6208e-04,  7.7987e-02,  8.7147e-02,  1.2109e-02, -6.1021e-02,\n",
      "          6.6308e-02,  3.6329e-02,  2.2981e-02,  5.2509e-02,  4.5800e-02,\n",
      "          5.1935e-02,  4.5096e-02,  2.0036e-02, -3.8186e-02,  1.9570e-02,\n",
      "         -9.2465e-02,  8.5632e-03,  6.8560e-02, -5.9228e-02,  7.5134e-02,\n",
      "         -5.2487e-02,  7.7378e-02,  4.7525e-02, -7.3721e-02,  4.3787e-02,\n",
      "          2.4390e-02,  4.8294e-02,  6.3230e-02, -2.1045e-02,  1.5429e-02,\n",
      "          2.3054e-02, -2.1525e-02,  4.7797e-02,  1.2166e-02, -6.3857e-02,\n",
      "         -7.6599e-02, -4.0119e-03, -1.5436e-02,  1.9469e-02,  6.5208e-02,\n",
      "         -3.3165e-03, -5.3649e-03,  8.3091e-02,  8.6375e-02, -9.8390e-02,\n",
      "         -1.5954e-03, -6.2846e-02,  5.9962e-02,  4.7078e-02, -7.3398e-02,\n",
      "          2.2832e-03, -1.2214e-02, -8.7766e-02,  1.0094e-01,  2.6266e-02,\n",
      "         -5.1930e-02,  2.9361e-02, -4.0511e-03,  2.9084e-02,  1.9398e-02,\n",
      "         -5.9775e-02, -1.4935e-02, -1.9328e-02,  8.8363e-02, -7.7855e-03,\n",
      "         -3.4996e-02],\n",
      "        [ 2.1266e-02,  7.1147e-02,  7.4068e-02,  4.8943e-02,  3.8053e-02,\n",
      "          3.3496e-02, -7.2217e-02,  4.0355e-02, -2.6867e-02,  1.3169e-02,\n",
      "         -7.5203e-02,  9.7264e-02,  3.0368e-02, -2.7433e-03, -4.4231e-02,\n",
      "          6.3232e-03,  1.0100e-01,  2.3639e-02,  7.4607e-02, -1.0665e-02,\n",
      "          3.1492e-02, -1.6009e-02,  5.2406e-02,  2.3068e-02,  1.7102e-02,\n",
      "         -5.9158e-02,  4.8066e-03, -8.5609e-03,  5.8536e-02, -2.7099e-02,\n",
      "          7.2412e-02, -6.9262e-02,  9.6545e-03,  1.0338e-03,  7.2990e-02,\n",
      "          2.7140e-03,  3.8255e-02, -6.3568e-03,  4.2050e-02, -3.1384e-02,\n",
      "         -4.6570e-02, -4.8463e-02,  4.1381e-02, -3.3933e-03,  8.1979e-02,\n",
      "          6.5036e-02, -7.0568e-02,  1.4426e-02,  1.0127e-01, -5.6129e-02,\n",
      "          9.5327e-02, -3.6243e-02,  3.2988e-02, -8.6561e-02,  1.6261e-02,\n",
      "         -9.7722e-02, -8.2596e-02,  8.9096e-02,  7.9995e-02, -2.6036e-02,\n",
      "          3.5425e-02,  9.7243e-02,  9.1177e-03, -8.5747e-02, -4.6977e-02,\n",
      "         -6.3933e-02,  3.7021e-02,  2.5785e-02, -3.9079e-02,  6.7113e-02,\n",
      "         -9.2092e-02, -6.6978e-02,  7.5619e-02, -9.7391e-02,  6.8728e-02,\n",
      "         -4.5333e-02, -9.0719e-02,  1.0958e-02,  8.0248e-02, -1.9829e-02,\n",
      "         -7.6009e-02, -5.3343e-02, -4.7183e-02,  4.0716e-02,  6.4248e-02,\n",
      "          7.6512e-02,  1.0084e-01,  2.6392e-02, -9.5451e-02,  8.6105e-02,\n",
      "          6.1785e-02,  8.7074e-02,  5.7171e-02, -5.2847e-02, -4.9093e-02,\n",
      "          5.5618e-02],\n",
      "        [-7.8619e-03,  9.4411e-02, -1.0168e-01, -6.5655e-02,  1.5171e-02,\n",
      "         -9.7622e-02, -5.0262e-02, -1.9934e-02,  8.8681e-02,  6.1969e-03,\n",
      "          9.9567e-02,  5.9372e-02,  2.0314e-02, -5.5042e-02, -5.6137e-02,\n",
      "         -1.4383e-02,  6.1634e-02, -5.3336e-02,  2.7667e-02, -5.2961e-02,\n",
      "         -9.0024e-03,  7.2629e-03, -9.1415e-02, -6.9108e-02, -2.1271e-02,\n",
      "         -5.7841e-02,  3.6771e-02,  6.9734e-02, -7.6715e-03,  8.3527e-02,\n",
      "          2.9524e-02,  2.0536e-02,  4.9575e-02,  1.8351e-02, -5.4781e-02,\n",
      "          1.3736e-03, -1.5453e-02,  5.2375e-03,  6.9113e-02,  1.7894e-02,\n",
      "          7.3616e-02, -1.1921e-02, -7.5879e-02,  1.3258e-02,  4.4102e-02,\n",
      "         -8.3141e-03,  2.8396e-02,  4.3195e-02,  5.5117e-02,  3.5417e-03,\n",
      "          8.7548e-02, -9.4199e-02, -1.6572e-02, -7.4709e-03, -1.0064e-01,\n",
      "          4.1275e-02, -8.2136e-02, -2.4267e-03, -2.4117e-02,  6.6609e-02,\n",
      "          8.0955e-03, -9.8050e-02,  4.5360e-02, -3.5184e-03, -1.4094e-02,\n",
      "         -5.6610e-02,  1.4725e-02,  8.2103e-02, -8.3532e-02, -9.0242e-02,\n",
      "          5.1140e-02, -9.6998e-04, -4.4278e-02, -9.9482e-02, -1.1320e-02,\n",
      "         -6.0900e-02,  1.7712e-02,  3.7446e-02,  9.9725e-02,  2.3735e-02,\n",
      "          5.3345e-02,  8.8586e-02,  3.7970e-02, -1.4781e-02,  8.1576e-02,\n",
      "          1.4366e-03, -1.1229e-03, -9.9080e-02, -2.7363e-02, -8.1028e-02,\n",
      "         -2.3113e-02, -6.8684e-02, -8.8659e-02,  7.4542e-02,  5.2583e-02,\n",
      "          3.8747e-02],\n",
      "        [ 1.4159e-03, -5.9294e-02, -4.8071e-02, -6.0788e-02, -4.3890e-02,\n",
      "          2.4969e-02,  2.2717e-02, -6.8922e-02, -1.0330e-02,  6.6140e-02,\n",
      "          9.0491e-02,  6.6283e-03, -4.8010e-02,  2.2474e-03, -2.0390e-02,\n",
      "          3.9663e-02,  6.4234e-02,  7.9873e-02, -4.0306e-02,  6.9418e-03,\n",
      "         -7.6138e-02,  3.9590e-02,  8.8249e-02,  3.0907e-02,  5.5471e-02,\n",
      "          7.1482e-02, -8.0969e-02, -8.8437e-02, -1.1074e-02,  6.5161e-02,\n",
      "          5.3195e-02, -7.0388e-02, -8.1399e-02,  7.2450e-02,  4.7831e-02,\n",
      "          8.8815e-02, -7.2538e-02, -3.5501e-03, -8.9259e-02, -4.6320e-02,\n",
      "         -6.4315e-02, -6.2169e-02,  3.0200e-02,  2.4477e-02, -6.9254e-02,\n",
      "          9.7831e-02, -7.6365e-02, -6.4905e-02, -1.6470e-02,  3.8275e-02,\n",
      "         -8.9273e-02, -3.3531e-02, -3.1883e-02, -2.8518e-02,  9.3296e-02,\n",
      "          2.3542e-02, -7.5094e-02, -1.2748e-02,  1.3617e-02,  7.7313e-02,\n",
      "          3.5586e-02, -4.0408e-02,  2.7144e-02,  9.1331e-02, -6.2026e-02,\n",
      "         -6.2761e-02, -9.3527e-02,  5.4598e-02, -3.8056e-02,  9.5068e-02,\n",
      "         -5.1559e-02, -2.9836e-02, -4.4229e-02, -4.9674e-02,  3.0546e-02,\n",
      "         -4.9440e-02, -1.9151e-02, -4.8456e-02, -9.5367e-02, -7.3551e-02,\n",
      "          8.7703e-02, -1.8620e-03, -3.5209e-03, -1.2352e-02, -8.2210e-02,\n",
      "         -1.4287e-02,  3.1231e-02, -8.8585e-02,  6.2226e-02, -6.3626e-02,\n",
      "         -9.0375e-02,  6.2512e-02, -1.0109e-01, -7.1333e-02, -2.1225e-02,\n",
      "          2.8185e-02],\n",
      "        [-8.9513e-02,  6.8115e-02, -1.4314e-02,  6.9894e-02,  3.9625e-02,\n",
      "         -2.1899e-02, -1.8957e-02,  5.3098e-02,  2.0686e-02, -6.0057e-02,\n",
      "          4.1315e-02,  4.5544e-02, -8.2774e-02,  8.7087e-02, -5.8051e-02,\n",
      "          8.0252e-02, -7.4204e-02,  8.8945e-02,  7.8536e-02,  3.3846e-02,\n",
      "          6.4235e-02, -1.9058e-02, -4.8633e-04, -2.8875e-02,  7.2617e-02,\n",
      "         -5.9942e-03, -9.8377e-02, -2.6522e-02,  4.9565e-02, -8.2922e-02,\n",
      "          7.2587e-02,  2.4104e-03, -3.8429e-02, -4.6130e-02,  1.0546e-02,\n",
      "          7.2179e-02, -5.6250e-02,  5.3518e-02, -9.8412e-03,  9.1795e-02,\n",
      "          8.9913e-02,  7.6286e-02,  8.0511e-02,  3.2299e-02,  9.4767e-02,\n",
      "         -5.5587e-02,  1.3350e-02,  9.7199e-02,  2.6482e-02, -6.9537e-02,\n",
      "         -5.8988e-02, -9.2743e-02,  6.1257e-02,  5.8158e-02, -7.7197e-02,\n",
      "         -5.1948e-04,  1.8610e-02,  8.4673e-02,  1.2848e-02, -6.2831e-03,\n",
      "          6.9964e-02,  1.7495e-02,  3.0291e-02,  3.5667e-02, -4.3274e-02,\n",
      "          8.7319e-02,  2.3340e-02,  5.8850e-02,  5.0668e-02, -3.7770e-02,\n",
      "         -8.2787e-02, -8.3402e-02,  2.9821e-02, -7.6917e-02,  9.1971e-02,\n",
      "          5.6098e-02, -4.7692e-02, -5.6955e-02,  8.1705e-02, -4.4977e-02,\n",
      "          4.8850e-02,  6.8712e-02,  8.7040e-02,  8.6103e-02, -8.8451e-02,\n",
      "         -4.8123e-02,  8.6329e-02, -4.5196e-02,  5.5902e-02,  1.7442e-02,\n",
      "          6.3840e-02,  8.5605e-03, -5.6684e-02, -1.2179e-03,  1.8447e-02,\n",
      "         -8.0456e-02]])\n",
      "Смещение\n",
      "tensor([ 0.1006,  0.0394, -0.0565, -0.0154,  0.0940,  0.0239,  0.0540,  0.0802,\n",
      "         0.0382, -0.0449])\n",
      "Результат tensor([[ 1.4290, -1.0707,  0.0729, -0.9104,  2.0161, -0.8326,  3.0872, -0.3406,\n",
      "         -1.3109,  2.2145]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target_model = TargetModel()\n",
    "output = target_model.forward(X).reshape(1,-1)\n",
    "target_model.getModelParams()\n",
    "print(f'Результат {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0127feb8-defb-4197-a9f3-915f02b3bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Линейный слой\n",
      "Веса\n",
      "tensor([[-5.8971e-02,  6.8141e-02,  3.1033e-02, -1.2944e-02, -1.7911e-02,\n",
      "          6.7453e-02,  2.4487e-02,  8.9585e-02, -8.8678e-02, -7.3682e-02,\n",
      "         -1.0134e-01, -7.8189e-02,  5.1757e-02, -9.7536e-02, -2.1583e-02,\n",
      "         -1.0133e-01, -4.5019e-02,  2.9161e-02,  3.7613e-02,  4.4074e-02,\n",
      "          4.7085e-02, -2.2691e-02, -3.0753e-02,  7.3225e-02, -2.5000e-02,\n",
      "          1.4456e-02, -9.1708e-02,  5.8287e-02,  6.3949e-02, -8.1443e-02,\n",
      "         -5.1507e-02,  8.6361e-02, -4.9946e-02,  2.2743e-03,  5.6640e-02,\n",
      "         -9.4879e-02, -9.9054e-02, -9.7921e-02, -7.1394e-02, -2.2157e-02,\n",
      "          7.4123e-02, -6.7019e-02, -4.9240e-02,  2.4058e-02,  1.6054e-02,\n",
      "         -7.6345e-04, -8.1809e-02,  8.2647e-02, -3.4222e-02,  2.5310e-02,\n",
      "          6.0694e-02, -6.3084e-02, -5.5161e-02,  1.0152e-01, -1.2629e-02,\n",
      "         -2.6366e-02, -8.2183e-02, -9.5567e-02, -4.6894e-02, -6.4551e-02,\n",
      "          5.7070e-02, -3.8669e-02, -5.4934e-03, -8.0043e-02,  5.2746e-02,\n",
      "          5.5442e-02, -1.3775e-02, -6.2656e-02,  3.4019e-03, -9.0506e-02,\n",
      "         -6.1319e-02, -9.1665e-02,  6.6084e-02, -5.2166e-02,  8.1343e-04,\n",
      "          4.3730e-02,  1.5642e-02, -3.3506e-02, -4.5516e-02, -2.6077e-05,\n",
      "          4.6307e-02,  8.8784e-02,  3.0016e-02, -5.6660e-02,  6.8321e-02,\n",
      "          6.3793e-02,  9.1795e-02, -5.1914e-02,  8.8366e-02,  2.6394e-02,\n",
      "          6.9395e-03, -9.1587e-03,  7.2292e-02, -8.1509e-02, -6.1100e-02,\n",
      "         -3.8863e-03],\n",
      "        [-6.6792e-02,  4.3802e-02, -3.0077e-01, -3.3485e-01, -2.2037e-01,\n",
      "         -6.7680e-01, -4.7528e-01, -2.0067e-01, -7.5750e-01, -4.2405e-01,\n",
      "         -1.9709e-01, -6.7474e-01, -1.8746e-01, -2.4677e-01, -2.3457e-01,\n",
      "         -2.6283e-03, -7.8259e-02, -3.1978e-01, -3.4502e-01, -1.8989e-01,\n",
      "          9.1601e-02, -3.6873e-01, -4.3529e-01, -3.9546e-01, -2.6658e-01,\n",
      "         -4.5807e-02, -4.0555e-01, -6.1381e-02, -3.4396e-01, -3.2604e-01,\n",
      "         -3.2027e-01, -3.5870e-01, -7.3813e-02, -9.0296e-02,  8.2272e-02,\n",
      "         -1.4461e-01,  2.3989e-02, -1.6227e-01, -2.5117e-01, -7.2114e-02,\n",
      "         -6.5104e-02, -1.5235e-01, -1.3478e-01, -4.9489e-02, -9.2069e-02,\n",
      "         -1.8966e-01, -3.1006e-01, -3.5029e-01, -6.7252e-01, -4.4550e-01,\n",
      "         -3.4162e-01, -9.8106e-02,  9.1029e-02, -1.3929e-01, -1.6144e-01,\n",
      "         -1.2051e-01, -9.2271e-02, -1.1169e-01, -6.2817e-01, -3.2778e-01,\n",
      "         -1.4533e-01, -3.1550e-01, -7.7309e-02, -5.5043e-01, -3.3515e-01,\n",
      "         -2.6901e-01, -2.5066e-01, -5.7263e-02, -2.1110e-01, -8.5525e-02,\n",
      "         -1.2760e-02, -1.1489e-01,  7.6320e-02, -1.5537e-01, -2.1575e-01,\n",
      "          1.2490e-02,  3.6844e-02, -2.6931e-01, -1.5785e-01,  4.0232e-02,\n",
      "          9.2920e-02, -8.5508e-02, -6.8002e-01, -6.1251e-03, -6.8287e-01,\n",
      "         -2.3538e-01, -2.7278e-01, -8.5281e-02, -7.5774e-01, -5.4758e-02,\n",
      "         -9.7702e-02, -2.3209e-01, -7.1444e-01,  4.7751e-03, -9.1736e-02,\n",
      "         -7.5290e-02],\n",
      "        [-4.9700e-02,  1.2428e-02,  2.5734e-02, -1.0122e-01,  9.5373e-02,\n",
      "         -2.3587e-02,  9.3015e-02, -5.2053e-02, -9.6815e-02, -6.2043e-02,\n",
      "          5.2139e-02, -7.1782e-02,  5.3472e-02, -5.5717e-02, -8.8066e-02,\n",
      "         -7.5336e-02,  1.4204e-02, -6.9262e-03, -4.1597e-03,  2.3479e-02,\n",
      "         -9.0110e-02,  5.4479e-02, -5.0505e-02, -3.6695e-03, -9.9572e-02,\n",
      "         -2.9203e-02, -5.6185e-02,  7.6108e-02, -6.4027e-02, -3.1961e-02,\n",
      "          4.0491e-02, -1.0170e-01,  3.0249e-02, -4.9790e-02, -5.5704e-02,\n",
      "          7.7763e-02, -5.0170e-03, -1.9146e-02,  4.4026e-02, -2.6834e-02,\n",
      "         -2.9558e-02,  1.8428e-02, -7.8550e-02,  1.8179e-02, -5.9324e-02,\n",
      "         -4.0960e-02,  6.3394e-02, -8.1762e-02, -4.2576e-02, -4.4560e-02,\n",
      "          5.7886e-02,  6.6542e-02,  9.2178e-02, -4.0209e-02, -4.9087e-03,\n",
      "         -4.7006e-02,  7.0246e-02, -9.1149e-02,  3.2975e-02, -5.1081e-02,\n",
      "          2.3640e-03,  8.7947e-02,  8.7942e-02,  4.5813e-02, -7.9593e-02,\n",
      "         -2.9406e-02, -6.8504e-02, -1.1556e-02, -8.4024e-02, -5.2136e-02,\n",
      "          7.6337e-02, -2.6957e-02,  6.1078e-02,  7.3643e-02, -4.0287e-02,\n",
      "         -4.1368e-02,  8.3722e-02, -6.9479e-02,  3.4048e-02,  2.3248e-02,\n",
      "         -6.7704e-02, -2.0470e-02,  6.6414e-02,  6.4399e-02, -6.6511e-02,\n",
      "         -9.6411e-02, -5.9856e-02,  2.2846e-02, -9.0576e-02, -8.9951e-02,\n",
      "          5.4314e-02,  7.1294e-02,  3.6044e-02,  7.7060e-02, -6.3128e-02,\n",
      "          4.2295e-02],\n",
      "        [ 1.0132e-01, -1.6845e-04,  3.5019e-01,  5.7360e-01,  3.8071e-01,\n",
      "          6.5777e-01,  6.7046e-01,  3.7906e-01,  9.5349e-01,  3.1931e-01,\n",
      "          2.5542e-01,  8.6386e-01,  1.0798e-01,  2.2801e-01,  2.5062e-01,\n",
      "          4.5887e-02,  9.4903e-02,  2.0974e-01,  4.5683e-01,  2.1804e-01,\n",
      "          5.1294e-02,  3.9989e-01,  6.5739e-01,  4.8562e-01,  2.8150e-01,\n",
      "          2.0207e-02,  5.1088e-01,  2.0185e-02,  3.2483e-01,  4.2276e-01,\n",
      "          2.4919e-01,  3.5369e-01,  2.3014e-01,  1.0199e-01,  9.1044e-02,\n",
      "          7.7347e-02,  8.5267e-02,  9.7196e-02,  1.9091e-01,  6.9655e-02,\n",
      "          4.2456e-02,  1.7439e-01,  1.7539e-02,  9.2305e-02,  1.2490e-01,\n",
      "          2.6254e-01,  3.8187e-01,  3.8721e-01,  7.8606e-01,  6.6448e-01,\n",
      "          2.4176e-01,  1.5702e-01, -8.4485e-02,  1.7585e-01,  1.9831e-01,\n",
      "          5.0702e-02,  2.6987e-02,  1.0696e-01,  6.1900e-01,  3.6850e-01,\n",
      "          1.0616e-01,  3.5413e-01,  2.5179e-01,  6.7333e-01,  3.0342e-01,\n",
      "          4.3442e-01,  1.7252e-01,  2.6467e-02,  2.9328e-01, -3.3294e-02,\n",
      "          1.5095e-01,  1.4785e-01,  2.5862e-02,  1.5722e-01,  1.8114e-01,\n",
      "          3.2010e-02,  6.5678e-02,  3.0984e-01,  2.2988e-01,  9.3218e-02,\n",
      "         -5.4002e-02,  1.9652e-01,  9.0987e-01,  1.9702e-01,  9.4526e-01,\n",
      "          2.3277e-01,  2.1804e-01,  1.0458e-01,  7.9630e-01,  4.2788e-03,\n",
      "          2.2975e-01,  3.2049e-01,  8.0674e-01, -8.2909e-02,  2.8858e-01,\n",
      "          1.1512e-01],\n",
      "        [ 3.9421e-02, -9.9292e-04, -4.4761e-03,  9.0224e-03,  4.8763e-02,\n",
      "         -8.3952e-02,  6.9108e-02, -9.9168e-02, -5.5118e-02, -9.2672e-02,\n",
      "          9.2084e-02, -2.8517e-03,  7.5996e-02, -9.1869e-02, -5.4341e-02,\n",
      "         -1.0902e-02, -2.7370e-02, -9.6274e-02,  1.4869e-02, -3.4295e-02,\n",
      "          9.9796e-02, -5.0072e-02, -4.9992e-02, -6.4732e-02, -6.5873e-03,\n",
      "          1.8373e-02,  5.6278e-02,  1.7356e-03,  5.8299e-02, -5.3494e-02,\n",
      "          9.5506e-05,  9.1208e-02, -3.7396e-03, -4.6145e-02, -3.9603e-03,\n",
      "          8.9692e-02,  3.7828e-02, -6.0875e-02, -1.2199e-02, -6.6305e-02,\n",
      "          6.5307e-02, -1.1674e-02, -2.0871e-02, -9.9591e-02, -7.6378e-02,\n",
      "         -1.1954e-02,  3.5821e-02, -5.5657e-02, -1.0570e-01, -3.7296e-02,\n",
      "          6.3567e-02,  8.7478e-03,  4.1098e-02,  2.9270e-02,  1.2041e-02,\n",
      "         -9.4254e-03, -2.6586e-03,  6.7211e-02, -2.1360e-02,  7.1342e-02,\n",
      "         -6.4773e-02,  6.6102e-02, -2.4045e-02,  1.3477e-02,  9.0449e-03,\n",
      "         -9.0364e-02,  6.4252e-03, -1.5482e-02,  1.6065e-02, -3.8626e-02,\n",
      "          3.6984e-02, -8.0145e-03,  3.9772e-02,  9.1518e-02,  3.8031e-02,\n",
      "          4.7055e-02, -6.4886e-02, -7.4451e-02,  4.3677e-02, -4.0058e-04,\n",
      "          8.7150e-02,  9.0548e-02,  3.3086e-02,  4.4894e-02, -1.0013e-01,\n",
      "          2.2948e-02,  8.3251e-02,  3.0914e-02,  4.5586e-02,  7.6250e-02,\n",
      "          6.3021e-02,  1.9098e-03,  5.4435e-02, -6.5379e-02, -2.9629e-02,\n",
      "          4.8894e-02],\n",
      "        [-5.7605e-02,  4.0978e-02, -3.6748e-03,  3.7577e-02,  7.6063e-02,\n",
      "         -3.0744e-02, -1.3120e-01, -4.1924e-02,  3.1126e-02,  5.3067e-02,\n",
      "         -1.0578e-01,  2.2027e-02,  8.9537e-02,  6.7190e-02,  5.8220e-02,\n",
      "         -7.6355e-02,  5.0009e-03,  2.4231e-03, -9.1008e-02, -4.0042e-03,\n",
      "         -2.1964e-02, -1.1237e-01,  3.9427e-02,  2.0641e-02, -1.2391e-01,\n",
      "         -5.6151e-02,  1.5688e-02, -8.6242e-02,  4.2497e-02,  2.1147e-02,\n",
      "         -1.0893e-01, -1.2378e-01, -1.9982e-02, -5.1015e-02,  2.6370e-02,\n",
      "          3.4786e-02, -2.3173e-02, -4.9184e-03, -8.3964e-02, -8.1755e-02,\n",
      "          1.5658e-02,  7.5024e-02,  3.9639e-02,  4.3921e-02,  2.6542e-03,\n",
      "          7.0175e-02,  8.1519e-03,  3.8082e-02, -4.0995e-03, -5.3137e-03,\n",
      "          1.2608e-03, -9.2352e-02, -5.3611e-02,  6.9363e-02, -3.0366e-02,\n",
      "         -2.7865e-02,  8.7337e-02, -4.5276e-02, -7.9857e-02, -4.2613e-02,\n",
      "         -9.2468e-02, -1.2146e-01, -8.7031e-03, -1.0879e-01,  7.4925e-02,\n",
      "          2.4448e-02,  2.1338e-02,  7.9939e-02,  3.2066e-03, -1.6038e-02,\n",
      "          7.8985e-02, -4.5771e-02, -7.5058e-02, -9.7924e-02,  2.9294e-02,\n",
      "         -7.2351e-02,  8.8888e-02, -1.0613e-01,  5.4326e-02,  4.4396e-02,\n",
      "          3.1035e-02,  4.6330e-02, -1.8156e-02, -5.0186e-02, -1.6219e-01,\n",
      "          3.8194e-02, -1.0901e-01, -3.1164e-02, -1.3180e-01,  7.2211e-02,\n",
      "          1.9460e-02,  4.7943e-02, -6.5403e-02,  2.9000e-02, -1.0779e-01,\n",
      "          4.7183e-02],\n",
      "        [ 4.5575e-02,  7.6095e-03,  4.6521e-02,  5.8474e-02, -1.4427e-02,\n",
      "         -7.7284e-02,  8.8157e-02,  3.6066e-02,  3.1253e-02,  4.5310e-02,\n",
      "         -9.0369e-04, -1.0145e-01, -3.4591e-02,  2.4692e-02,  2.7057e-02,\n",
      "          5.8683e-02, -8.4117e-02, -1.0559e-02, -9.4951e-02,  2.3804e-02,\n",
      "         -9.0579e-03, -2.2868e-02,  9.4708e-02,  6.7518e-02,  6.4047e-02,\n",
      "         -8.2082e-02,  5.8169e-02, -9.8191e-03, -2.7245e-02, -8.3080e-02,\n",
      "         -9.9665e-02,  5.7729e-02, -5.2486e-02, -8.4236e-02,  8.6437e-02,\n",
      "         -1.0015e-01,  4.6858e-02, -6.1370e-02,  1.1590e-02, -2.5585e-02,\n",
      "          1.8602e-02, -4.1780e-02, -7.9639e-02, -7.3962e-02,  8.8813e-02,\n",
      "         -4.6644e-02, -9.3642e-02, -2.1907e-02, -6.3197e-02, -6.2921e-02,\n",
      "          3.1710e-02,  8.4346e-02,  4.6794e-02,  6.7733e-02,  9.3795e-02,\n",
      "          4.3828e-02, -3.6095e-03,  8.2930e-03,  1.4997e-02,  4.3867e-02,\n",
      "         -2.9304e-02, -5.2587e-02, -5.0104e-02, -7.5988e-02,  1.0732e-02,\n",
      "         -1.1239e-02,  6.2779e-02,  2.7722e-02,  5.3449e-02,  4.2311e-02,\n",
      "         -5.3035e-02, -1.0029e-01,  8.9710e-02, -1.0199e-01, -2.2614e-02,\n",
      "         -8.4290e-02,  6.0414e-02, -3.0992e-02,  3.0289e-02,  6.7593e-02,\n",
      "         -8.1512e-02, -2.3435e-02, -8.6384e-02,  2.5561e-02,  1.0607e-02,\n",
      "         -3.7465e-02,  1.4658e-02,  4.0417e-03,  4.9821e-02,  4.5934e-02,\n",
      "          1.8112e-02,  4.8083e-02,  5.9417e-02,  3.3189e-02,  8.9855e-02,\n",
      "          5.6083e-02],\n",
      "        [ 3.2264e-02, -7.3035e-03,  6.4094e-02, -1.4987e-03, -8.5024e-02,\n",
      "          2.2646e-02, -6.6340e-02,  3.5278e-02,  5.3592e-02, -9.0493e-02,\n",
      "         -7.0096e-02,  7.7965e-02, -3.3448e-03, -2.8908e-02,  5.0544e-02,\n",
      "         -5.2196e-02,  5.4627e-02, -8.9392e-02, -6.1463e-02, -5.5388e-02,\n",
      "         -5.0192e-02,  9.6499e-02,  7.9166e-02,  3.7942e-02, -6.6814e-03,\n",
      "          2.5975e-02,  6.1565e-02, -4.1753e-02,  8.2443e-02, -7.2331e-03,\n",
      "          9.5763e-02, -8.8575e-02,  4.7978e-02,  9.1238e-02, -1.0120e-01,\n",
      "          6.6481e-02,  6.8920e-02,  3.5152e-02,  8.3741e-02,  9.7497e-02,\n",
      "          1.2581e-02, -9.0528e-02, -6.6694e-02,  8.3121e-02, -3.4384e-02,\n",
      "          5.4146e-02,  5.6374e-03,  6.4936e-02, -5.0507e-02,  3.9145e-03,\n",
      "         -7.0290e-02, -7.8007e-02,  1.0454e-02, -4.4359e-02,  3.6711e-02,\n",
      "          1.2450e-02,  4.8062e-02, -6.0925e-02, -7.7293e-02, -4.8320e-02,\n",
      "         -4.2823e-02,  7.5909e-02,  2.7930e-03, -2.2254e-02, -2.5616e-02,\n",
      "         -8.8038e-02, -6.1283e-02,  8.1707e-02, -8.5260e-02,  6.6983e-02,\n",
      "          6.4232e-02, -8.2228e-02, -9.0686e-02, -5.3431e-02,  3.2398e-02,\n",
      "          2.6278e-02,  1.0762e-02, -4.8446e-02, -6.9093e-02, -3.6193e-02,\n",
      "         -3.0932e-02, -4.6608e-02,  3.0754e-02,  5.7082e-02,  7.9458e-02,\n",
      "         -7.7784e-02, -1.0015e-01,  7.7224e-02, -4.5369e-02, -5.5068e-03,\n",
      "         -2.0577e-02, -8.1383e-02, -1.6137e-02, -4.7619e-02, -8.6150e-02,\n",
      "          1.4380e-02],\n",
      "        [ 1.3385e-02, -8.3379e-02, -2.2237e-02, -1.4491e-03, -7.8280e-02,\n",
      "         -6.9425e-02, -8.8214e-02, -1.5403e-02,  6.4178e-02, -7.6812e-02,\n",
      "         -5.5345e-03,  5.1545e-02, -1.2545e-02, -9.4431e-02, -7.7141e-02,\n",
      "          4.9834e-02,  8.9414e-02,  8.0207e-02, -4.5198e-02,  1.0121e-01,\n",
      "         -5.3188e-02,  6.0174e-02,  6.3528e-02,  2.5055e-03,  8.5476e-02,\n",
      "         -4.5964e-02, -6.5638e-03,  7.5337e-02, -2.4701e-02,  7.6081e-02,\n",
      "          4.1160e-03, -7.0404e-02, -9.5569e-02,  4.3692e-02,  7.7484e-02,\n",
      "          8.1091e-02,  9.5626e-02,  1.0315e-02,  2.7396e-02, -2.4866e-02,\n",
      "          7.3062e-02,  8.7887e-02,  3.5495e-02, -3.9488e-02,  2.4814e-02,\n",
      "         -9.8119e-02, -7.7237e-02, -8.3296e-02, -5.1011e-02, -6.1036e-02,\n",
      "         -2.9251e-02,  8.7254e-02, -8.6262e-02,  3.8455e-02,  1.8752e-02,\n",
      "          8.0250e-03, -7.7422e-02,  9.0897e-02,  1.9553e-02, -3.5448e-02,\n",
      "         -5.0140e-02,  5.8612e-02,  1.0730e-02, -4.9303e-02,  9.7777e-02,\n",
      "         -2.0810e-02, -9.2682e-02, -9.1207e-02, -6.1003e-02, -7.1930e-02,\n",
      "         -6.9468e-02, -2.4214e-03,  5.3368e-02,  5.6369e-02, -1.1075e-02,\n",
      "         -9.2571e-03, -6.8675e-02, -6.2112e-02,  1.5486e-02,  5.4339e-02,\n",
      "         -8.6836e-02, -6.1007e-02,  1.3431e-02, -1.8696e-02, -6.0766e-02,\n",
      "          8.7385e-02,  5.1791e-02,  9.5958e-02,  6.9400e-02, -1.4136e-02,\n",
      "          8.6211e-02,  8.2431e-02, -6.0987e-02, -6.2556e-02, -6.4980e-02,\n",
      "         -3.9291e-02],\n",
      "        [ 4.6747e-02, -4.9640e-02, -1.2235e-02, -6.9542e-02,  7.2067e-02,\n",
      "          7.0044e-02,  8.8918e-05,  7.9078e-02,  4.8098e-02, -7.1626e-02,\n",
      "         -4.8234e-02, -1.0265e-01,  3.2522e-02,  6.5052e-02, -4.1792e-02,\n",
      "         -1.2858e-02,  8.2766e-02, -4.4458e-02, -7.0155e-03,  7.7739e-02,\n",
      "          8.0907e-02,  6.0274e-03,  8.7884e-02,  1.7268e-02, -4.0030e-02,\n",
      "         -7.9586e-02,  8.9365e-02,  7.8719e-02, -4.3088e-03, -1.6176e-02,\n",
      "          5.8520e-02,  4.5044e-05, -7.1300e-02,  2.4837e-02, -3.5812e-02,\n",
      "         -3.4496e-02,  4.3719e-02, -8.6717e-02,  7.9289e-02,  1.0164e-01,\n",
      "         -4.2066e-02, -7.6310e-03,  2.4011e-02, -7.1185e-03, -9.7059e-02,\n",
      "          9.8085e-02, -3.4798e-02, -3.2557e-02,  6.6177e-02, -8.4137e-02,\n",
      "          7.1086e-02,  5.6646e-02,  5.0511e-02, -4.2594e-02, -6.6398e-02,\n",
      "          5.8766e-02,  8.8082e-02, -9.7830e-02, -7.1192e-02,  3.1856e-02,\n",
      "          2.4417e-02, -3.6614e-02, -1.0155e-01, -6.9889e-02,  6.2565e-02,\n",
      "          3.7958e-02, -1.6934e-02, -8.8223e-02, -4.9112e-02,  4.4068e-02,\n",
      "         -6.4199e-02, -4.4812e-02,  5.9840e-02,  5.6333e-02, -5.8731e-02,\n",
      "         -5.0462e-02,  9.7090e-02, -6.5453e-02,  2.4583e-02, -8.0598e-02,\n",
      "         -8.0966e-02,  7.6565e-02,  1.6886e-02, -8.0268e-02,  5.5321e-02,\n",
      "          4.2705e-02, -7.8719e-02, -7.4401e-02, -4.2354e-02,  5.5051e-02,\n",
      "         -8.7772e-02, -1.1019e-02, -6.2743e-02, -5.1082e-02,  3.9403e-02,\n",
      "          4.3284e-03]])\n",
      "Смещение\n",
      "tensor([-0.0700, -0.0135,  0.0506,  0.0055, -0.0270,  0.0535, -0.0701,  0.0206,\n",
      "         0.0408,  0.0466])\n"
     ]
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(target_model.parameters(), lr=0.1)\n",
    "\n",
    "loss = loss_function(output, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "target_model.getModelParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e624d413-2f1b-4086-ac4d-261e17fbf497",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FlattenLayer' object has no attribute 'output_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Ulayers.add_module('linear', lin)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m Ulayers\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mUlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mРезультат \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FlattenLayer' object has no attribute 'output_'"
     ]
    }
   ],
   "source": [
    "conv = Conv2DLayer(2,5,3,'ReLU','random')\n",
    "#conv.weights_, conv.bias_ = target_model.getConvParams()\n",
    "\n",
    "#lin = LinearLayer(96, 10, 'linear', 'zeros')\n",
    "#lin.weights_, lin.bias_ = target_model.getLinearParams()\n",
    "\n",
    "Ulayers = LayerSequential()\n",
    "Ulayers.add_module('Conv2D', conv)\n",
    "Ulayers.add_module('maxPool2D', MaxPool2DLayer(2))\n",
    "Ulayers.add_module('flatten', FlattenLayer())\n",
    "#Ulayers.add_module('linear', lin)\n",
    "Ulayers.forward(X)\n",
    "output = Ulayers[-1].output_.reshape(1,-1)\n",
    "print(f'Результат {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21886ec-9ed8-456c-90d7-34f992b1ad3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461de0e9-e4ae-4651-bdb0-3f71c90006fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c116418-5a9e-417a-be61-ae3125986720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184ae39-82ca-4f4e-bb3b-74178baa2fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1f11789-4cad-4a62-88e6-5767ea19ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DLayer:\n",
    "    def __init__(self, kernel_size, start_weights):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weights_ = self._start_weights_type[start_weights]((kernel_size, kernel_size))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Conv2DLayer(kernel_size=({self.kernel_size},{self.kernel_size}))'\n",
    "\n",
    "    @staticmethod\n",
    "    def _makeConvolution(channel, kernel):\n",
    "        k = kernel.shape[0]\n",
    "        n = channel.shape[0] - k + 1\n",
    "        m = channel.shape[1] - k + 1\n",
    "        return torch.tensor([[torch.sum(channel[row:row+k, col:col+k]*kernel) for col in range(m)]\n",
    "                            for row in range(n)])\n",
    "\n",
    "    def layerForward(self, X):\n",
    "        return self._makeConvolution(X, self.weights_)\n",
    "\n",
    "    @staticmethod\n",
    "    def _zeroStartWeights(shape):\n",
    "        return torch.zeros(shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def _randomStartWeights(shape):\n",
    "        return torch.randn(shape)\n",
    "    \n",
    "    _start_weights_type = {'zeros': _zeroStartWeights,\n",
    "                           'random': _randomStartWeights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62f317ab-494c-4f55-a0c4-7bbf26260555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2DLayer:\n",
    "    def __init__(self, kernel_size=2):\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def layerForward(self, X):\n",
    "        return self._maxPooling(X)\n",
    "    \n",
    "    def _maxPooling(self, channel):\n",
    "        result = torch.tensor([[torch.max(channel[row-self.kernel_size:row, col:col+self.kernel_size]) \n",
    "                                for col in range(0, channel.shape[1], self.kernel_size)]\n",
    "                               for row in range(0, channel.shape[0], self.kernel_size)])\n",
    "        return result\n",
    "\n",
    "class FlattenLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def layerForward(self, X):\n",
    "        return X.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c132d3a-6713-4695-be98-94b0b7db3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = torch.tensor([[1,0,3,5,4,5,6],\n",
    "                        [9,4,3,8,8,7,3],\n",
    "                        [0,3,5,2,4,3,2],\n",
    "                        [3,1,5,0,1,7,4],\n",
    "                        [2,2,0,1,0,2,2]],\n",
    "                       dtype=torch.float32)\n",
    "\n",
    "channel_torch = torch.tensor([[[1,0,3,5,4,5,6],\n",
    "                               [9,4,3,8,8,7,3],\n",
    "                               [0,3,5,2,4,3,2],\n",
    "                               [3,1,5,0,1,7,4],\n",
    "                               [2,2,0,1,0,2,2]]],\n",
    "                             dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ecb96b2-cc33-4bba-b7ad-2deab6b3f63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch result\n",
      "tensor([[[-0.7586, -0.3328]]], grad_fn=<MaxPool2DWithIndicesBackward0>)\n",
      "My result\n",
      "tensor([[-2.2781, -1.9299, -1.6958, -3.7991, -2.4279],\n",
      "        [-0.7586, -2.2678, -0.3328, -2.0301, -4.2719],\n",
      "        [-0.8114, -1.2358, -1.2547, -0.7473, -2.6943]])\n"
     ]
    }
   ],
   "source": [
    "seq = torch.nn.Sequential()\n",
    "seq.add_module('conv2d', torch.nn.Conv2d(1,1,3,bias=False))\n",
    "seq.add_module('max_pool', torch.nn.MaxPool2d(2))\n",
    "print(f'Torch result\\n{seq(channel_torch)}')\n",
    "\n",
    "u_seq = LayerSequential()\n",
    "u_seq.add_module('conv2d', Conv2DLayer(3, 'random'))\n",
    "#u_seq.add_module('max_pool', MaxPool2DLayer(2))\n",
    "u_seq[0].weights_ = seq[0].weight.data[0][0]\n",
    "print(f'My result\\n{u_seq.forward(channel)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ecee605-9ee1-46ef-bb45-fef046666fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d36ff06a-c6c7-449c-9e58-0ce8d4bc7aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3311,  0.0564, -0.3074],\n",
       "        [ 0.2913,  0.0502, -0.1719],\n",
       "        [ 0.0789, -0.1571,  0.2572]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_seq[0].weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56654896-497d-4bca-ab72-408cac57ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
